{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5934b256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ankit\n",
      "[nltk_data]     Shah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\python310\\lib\\site-packages (0.1.87)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\python310\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.5.1 in c:\\python310\\lib\\site-packages (from yfinance) (4.9.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\python310\\lib\\site-packages (from yfinance) (1.4.3)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in c:\\python310\\lib\\site-packages (from yfinance) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\python310\\lib\\site-packages (from yfinance) (1.23.2)\n",
      "Requirement already satisfied: requests>=2.26 in c:\\python310\\lib\\site-packages (from yfinance) (2.28.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\python310\\lib\\site-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python310\\lib\\site-packages (from pandas>=0.24.0->yfinance) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.24.0->yfinance) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests>=2.26->yfinance) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests>=2.26->yfinance) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\python310\\lib\\site-packages (from requests>=2.26->yfinance) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests>=2.26->yfinance) (3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "\n",
    "import contractions\n",
    "import os\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing  import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from nltk.corpus import stopwords    \n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, SpatialDropout1D, MaxPooling1D, Conv1D, Concatenate, Bidirectional, GlobalMaxPool1D, ActivityRegularization, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score,confusion_matrix, classification_report\n",
    "\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nlpaug\n",
    "import nlpaug.augmenter.word as nlpaw\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "!pip install yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0468b11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cab3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/Transcripts'\n",
    "df = pd.DataFrame()\n",
    "companies = {'AMZN':'Amazon',\n",
    " 'AAPL':'Apple',\n",
    " 'INTC':'Intel',\n",
    " 'MU':'Micron',\n",
    " 'GOOGL': 'Alphabet',\n",
    " 'MSFT': 'Microsoft',\n",
    " 'AMD':'AMD',\n",
    " 'ASML':'ASML',\n",
    " 'NVDA':'NVIDIA',\n",
    " 'CSCO':'Cisco'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0acae6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "tf = 0\n",
    "totalsummary = ''\n",
    "totalqna = ''\n",
    "for comp in os.listdir(path):\n",
    "    if comp!='.DS_Store':\n",
    "        company = comp\n",
    "        files = os.listdir(path+'/'+company)\n",
    "        for j in files:\n",
    "            allinfo = []\n",
    "            with open(path+'/'+company+'/'+j) as f:\n",
    "                lines = f.readlines()\n",
    "                summary = []\n",
    "                qna = []\n",
    "                i = 0\n",
    "                while i<len(lines):\n",
    "                    if lines[i]=='\\n':\n",
    "                        i+=1\n",
    "                    elif lines[i][:3]=='===':\n",
    "                        i+=1\n",
    "                    elif 'operator' in lines[i].lower():\n",
    "                        i+=3\n",
    "                    elif lines[i][:3] == '---':\n",
    "                        i+=1\n",
    "                    elif 'presentation' in lines[i].lower():\n",
    "                        i+=2\n",
    "#                         print(j)\n",
    "                        while i<len(lines):\n",
    "#                             print(lines[i])\n",
    "                            if '===' in lines[i]:\n",
    "                                break\n",
    "                            if 'Questions and Answers' in lines[i]:\n",
    "                                break\n",
    "                            elif lines[i]=='\\n':\n",
    "                                i+=1\n",
    "                                continue\n",
    "                            elif 'operator' in lines[i].lower():\n",
    "                                i+=3\n",
    "                            elif '---' in lines[i]:\n",
    "                                i+=1\n",
    "                            summary.append(lines[i].rstrip())\n",
    "                            i+=1\n",
    "                    \n",
    "                    elif '[' in lines[i] and companies[company].lower() in lines[i].lower():\n",
    "                        i+=2\n",
    "                        while lines[i][:3]!='---':\n",
    "                            if lines[i]=='\\n':\n",
    "                                i+=1\n",
    "                                continue\n",
    "                            summary.append(lines[i].rstrip())\n",
    "                            i+=1\n",
    "                    \n",
    "                    elif 'Questions and Answers' in lines[i]:\n",
    "                        i+=1\n",
    "                        while i<len(lines):\n",
    "                            if lines[i]=='\\n':\n",
    "                                i+=1\n",
    "                            elif 'Operator' in lines[i]:\n",
    "                                i+=2\n",
    "                            elif lines[i][:3] == '---':\n",
    "                                i+=1\n",
    "                            elif '[' in lines[i]:\n",
    "                                i+=2\n",
    "                            else:\n",
    "                                qna.append(lines[i].rstrip())\n",
    "                                i+=1\n",
    "                    \n",
    "                    elif '[' in lines[i] and companies[company].lower() not in lines[i].lower():\n",
    "                        while i<len(lines):\n",
    "                            if lines[i]=='\\n':\n",
    "                                i+=1\n",
    "                            elif 'Operator' in lines[i]:\n",
    "                                i+=3\n",
    "                            elif lines[i][:3] == '---':\n",
    "                                i+=1\n",
    "                            elif '[' in lines[i]:\n",
    "                                i+=2\n",
    "                            else:\n",
    "                                qna.append(lines[i].rstrip())\n",
    "                                i+=1\n",
    "                    else:\n",
    "                        i+=1\n",
    "                \n",
    "                if lines[0][0] == 'Q':\n",
    "                    quarter = lines[0].split(' ')[0]\n",
    "                    year = lines[0].split(' ')[1]\n",
    "                else:\n",
    "                    quarter = lines[1].split(' ')[0]\n",
    "                    year = lines[1].split(' ')[1]\n",
    "                cleansummary = []\n",
    "#                 print(j)\n",
    "                for i in range(len(summary)):\n",
    "                    if '--' in summary[i]:\n",
    "                        i+=1\n",
    "                    elif 'Operator' in summary[i]:\n",
    "                        i+=3\n",
    "                    elif '[' in summary[i]:\n",
    "#                         print(i, summary[i])\n",
    "                        i+=1\n",
    "                    else:\n",
    "                        cleansummary.append(summary[i])\n",
    "                summary_para = ' '.join(cleansummary).rstrip()\n",
    "                qna_para = ' '.join(qna).rstrip()\n",
    "                totalsummary += summary_para\n",
    "                totalqna = qna_para\n",
    "                allinfo.append(quarter)\n",
    "                allinfo.append(year)\n",
    "                allinfo.append(companies[company])\n",
    "                allinfo.append(summary_para)\n",
    "                allinfo.append(qna_para)\n",
    "                df.append(allinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fba003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_transcript_df = pd.DataFrame(df)\n",
    "earnings_transcript_df.columns =['Quarter','Year','Company','Summary','Q&A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "781bd569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Q&amp;A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Good day, everyone, and welcome to t...</td>\n",
       "      <td>My first question was actually just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>I. 1Q16 Business Review (T.C.)       1. Highli...</td>\n",
       "      <td>&lt;Sync id=\"L166\"/&gt;Hello.  &lt;Sync id=\"L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>I. Annotation (N.P)       1. Detail:          ...</td>\n",
       "      <td>Thank you very much for the question. Tim, can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>I. 4Q16 Business Review (T.C.)       1. Highli...</td>\n",
       "      <td>Good afternoon and congratulations. Tim, now t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Apple</td>\n",
       "      <td>I. 3Q17 Review (T.C.)       1. Highlights:    ...</td>\n",
       "      <td>&lt;Sync id=\"L153\"time=\"00:25:09\"/&gt;Luca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2020</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>I'll now turn the call over to Simona Jankowsk...</td>\n",
       "      <td>Colette, I was wondering if you coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2020</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>I'll now turn the call over to Simona Jankowsk...</td>\n",
       "      <td>For my first one, you mentioned that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2021</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>Simona Jankowski, you may begin your conferenc...</td>\n",
       "      <td>Congratulations on the strong growth and execu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2020</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>Thank you. Good afternoon, everyone...</td>\n",
       "      <td>I guess on data center, Colette or J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2021</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>Simona Jankowski, you may begin your conferenc...</td>\n",
       "      <td>Congratulations on a solid quarter. Colette, I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Quarter  Year Company                                            Summary  \\\n",
       "0        Q2  2016   Apple            Good day, everyone, and welcome to t...   \n",
       "1        Q1  2016   Apple  I. 1Q16 Business Review (T.C.)       1. Highli...   \n",
       "2        Q3  2016   Apple  I. Annotation (N.P)       1. Detail:          ...   \n",
       "3        Q4  2016   Apple  I. 4Q16 Business Review (T.C.)       1. Highli...   \n",
       "4        Q3  2017   Apple  I. 3Q17 Review (T.C.)       1. Highlights:    ...   \n",
       "..      ...   ...     ...                                                ...   \n",
       "183      Q1  2020  NVIDIA  I'll now turn the call over to Simona Jankowsk...   \n",
       "184      Q3  2020  NVIDIA  I'll now turn the call over to Simona Jankowsk...   \n",
       "185      Q2  2021  NVIDIA  Simona Jankowski, you may begin your conferenc...   \n",
       "186      Q4  2020  NVIDIA             Thank you. Good afternoon, everyone...   \n",
       "187      Q1  2021  NVIDIA  Simona Jankowski, you may begin your conferenc...   \n",
       "\n",
       "                                                   Q&A  \n",
       "0              My first question was actually just ...  \n",
       "1              <Sync id=\"L166\"/>Hello.  <Sync id=\"L...  \n",
       "2    Thank you very much for the question. Tim, can...  \n",
       "3    Good afternoon and congratulations. Tim, now t...  \n",
       "4              <Sync id=\"L153\"time=\"00:25:09\"/>Luca...  \n",
       "..                                                 ...  \n",
       "183            Colette, I was wondering if you coul...  \n",
       "184            For my first one, you mentioned that...  \n",
       "185  Congratulations on the strong growth and execu...  \n",
       "186            I guess on data center, Colette or J...  \n",
       "187  Congratulations on a solid quarter. Colette, I...  \n",
       "\n",
       "[188 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earnings_transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f844d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = Counter(totalsummary.split(' '))\n",
    "words += Counter(totalqna.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57258f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 49.678204038670316, ease: 'difficult', grade_levels: ['college']\n",
      "score: 14.0770290173987, grade_level: 'college'\n"
     ]
    }
   ],
   "source": [
    "from readability import Readability\n",
    "r = Readability(earnings_transcript_df.iloc[0,3])\n",
    "r.flesch_kincaid()\n",
    "print(r.flesch())\n",
    "print(r.gunning_fog())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "708dae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgTxtLen(df):\n",
    "    avg_length_summary_after_preprocessing = str(df['Summary'].str.len().mean()) \n",
    "    avg_length_qna_after_preprocessing = str(df['Q&A'].str.len().mean()) \n",
    "    print(avg_length_summary_after_preprocessing)\n",
    "    print(avg_length_qna_after_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0412dc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove URLS\n",
      "16292.77659574468\n",
      "28507.675531914894\n",
      "remove HTML tags\n",
      "16292.771276595744\n",
      "28088.38829787234\n",
      "remove extra whitespaces\n",
      "16292.771276595744\n",
      "28088.38829787234\n",
      "remove contractions\n",
      "16066.127659574468\n",
      "27840.452127659573\n",
      "Remove characters following digits such as 1st, 2nd or 3rd\n",
      "16066.127659574468\n",
      "27840.452127659573\n",
      "Replace hyphens with space\n",
      "16066.127659574468\n",
      "27840.452127659573\n",
      "remove non alphabetical characters\n",
      "16066.127659574468\n",
      "27840.452127659573\n"
     ]
    }
   ],
   "source": [
    "def strip_html_tags(text): \n",
    "    soup = BeautifulSoup(text, \"html.parser\") \n",
    "    stripped_text = soup.get_text(separator=\" \") \n",
    "    return stripped_text \n",
    "    \n",
    "# Make lowercase\n",
    "earnings_transcript_df[\"Summary\"] = earnings_transcript_df[\"Summary\"].str.lower()\n",
    "earnings_transcript_df[\"Q&A\"] = earnings_transcript_df[\"Q&A\"].str.lower()\n",
    "\n",
    "# Remove URLS\n",
    "earnings_transcript_df['Summary']= earnings_transcript_df['Summary'].str.replace('http(s)?:\\/\\/.*', '', regex=True)\n",
    "earnings_transcript_df['Q&A']= earnings_transcript_df['Q&A'].str.replace('http(s)?:\\/\\/.*', '', regex=True)\n",
    "print(\"Remove URLS\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# remove HTML tags\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].apply(lambda x: strip_html_tags(x))\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].apply(lambda x: strip_html_tags(x))\n",
    "print(\"remove HTML tags\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# remove extra whitespaces\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].replace(r'/\\s/\\s+/g', ' ', regex=True)\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].replace(r'/\\s/\\s+/g', ' ', regex=True)\n",
    "print(\"remove extra whitespaces\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# remove contractions\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].apply(lambda x: ' '.join([contractions.fix(word) for word in x.split()]))\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].apply(lambda x: ' '.join([contractions.fix(word) for word in x.split()]))\n",
    "print(\"remove contractions\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# Remove characters following digits such as 1st, 2nd or 3rd\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].str.replace('\\b\\d+\\w+\\b', '', regex=True)\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].str.replace('\\b\\d+\\w+\\b', '', regex=True)\n",
    "print(\"Remove characters following digits such as 1st, 2nd or 3rd\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# Replace hyphens with space\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].replace('/\\b-\\b/g', ' ', regex=True)\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].replace('/\\b-\\b/g', ' ', regex=True)\n",
    "print(\"Replace hyphens with space\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# remove non alphanumeric characters\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].str.replace('[^a-zA-Z0-9 ]', ' ')\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].str.replace('[^a-zA-Z0-9 ]', ' ')\n",
    "print(\"remove non alphabetical characters\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aec14a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earnings_transcript_df.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "180dc732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords\n",
      "8878.675531914894\n",
      "10111.771276595744\n",
      "Lemmatize\n",
      "8878.595744680852\n",
      "10111.670212765957\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "additional_stop_words= ['good', 'welcome','also', 'data', 'across', 'google', 'see', 'learn', 'website', 'co', 'iphone', 'devices', 'windows', 'generation', 'every', 'gpu', 'everyone', 'create','office', 'server', 'give', 'around', 'relate', 'saw', 'press', 'applications', 'available','software', 'systems', 'youtube', 'microsoft', 'nanometer', 'search', 'please',  'partner', 'helf', 'game', 'use', 'thank', 'apple', 'nand', 'sequentially','pc', 'would', 'azure', 'information',  'work', 'reflect', 'mobile', 'prior', 'platform', 'security', 'conference', 'ago', 'focus', 'mix', '2018', '2017', '2016', 'come', 'experience', 'solutions', 'memory','dram', 'let', 'primarily'  'remain', 'look', 'technology', 'compute', 'help', 'ai', 'today','us', 'like', 'think', 'see', 'go', 'question', 'would', 'us', 'look', 'say', 'come', 'really', 'get', 'thank', 'talk', 'also', 'yes', 'give', 'make', 'bite', 'could', 'take', 'want', 'kind', 'line', 'know', 'back', 'center', 'around', 'end', 'still', 'mean', 'actually', 'way', 'side', 'today', 'use', 'part', 'overall', 'need', 'sure', 'obviously', 'increase', 'follow', 'focus', 'level', 'company', 'game', 'base', 'sort', 'help', 'mix', 'mention', 'comment', 'different', 'euv', 'let', 'even', 'course', 'dram', 'across', 'move', 'compute', 'nanometer', 'learn', 'share', 'important', 'guess', 'believe', 'feel', 'pretty', 'world', 'couple', 'understand', 'saw', 'may', 'china', 'wonder', 'versus', 'try', 'memory', 'many', 'please', 'happen', 'quite', 'prime', 'trend', 'whether', 'basis', 'capacity', 'nand', 'view', 'tool', 'model', 'software', 'probably', 'guy', 'put', 'able', 'ask', 'team', 'thing', 'plan', 'certainly', 'something', 'network', 'day', 'okay', 'server', 'order', 'guide', 'relate', 'early', 'every', 'gpu', 'capex', 'platform', 'earlier', 'provide', '2019', 'areas', 'always', 'mobile', 'bring', 'reason', 'third', 'transition', 'experience', 'applications', 'excite', 'might', 'fact', 'position', 'do', 'ago', 'azure', 'color', 'environment', 'pc', 'play', 'past', 'process', 'partner', 'iphone', 'answer', 'months', 'future', 'curious', 'google', 'within', 'lead', 'sense', '2018', 'include', 'relative', 'longer', 'program', 'support', 'tell', 'strength', 'content', 'layer', 'already', 'hear', 'machine', 'seem', 'search', 'anything', 'target', 'mark', 'helpful', 'channel', 'systems', 'architecture', 'offer', 'factor', 'example', 'particularly', 'design', 'clearly', 'place', 'keep', 'graphics', 'node', 'ability', 'open', 'users', 'youtube', 'create', 'become', 'particular', '2017', 'real', 'issue', 'perspective', 'interest', 'area', 'another', 'case', 'amount', 'amazon', 'aws', 'less', 'announce', 'several', 'fourth', 'generation', 'key', 'gpus', 'video', 'apple', 'platforms', 'upgrade', 'type', 'show', 'deal', 'store', 'clear', 'set', 'especially', 'map', 'update', 'kelly', 'compare', 'buy', 'beyond', 'logic', 'step', 'unit', 'security', 'basically', 'everything', 'r', 'remain', 'approach', 'specific', 'standpoint', 'sundar', 'definitely', 'far', 'together', 'assume', '2016', 'devices', 'custom', 'piece', 'adoption', 'prepare', 'front', '365', 'ryzen', 'digit', 'yet', 'sequentially', 'expectations', 'perhaps', 'india', 'brian', 'remark', 'days', '3d', 'general', '18', 'conclude', 'asps']\n",
    "stop_words.extend(additional_stop_words)\n",
    "#print(stop_words)\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].astype('string')\n",
    "\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words) ]))\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].astype('string')\n",
    "\n",
    "print(\"Stopwords\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "preprocessed_summary = \"\"\n",
    "\n",
    "for summary in earnings_transcript_df[\"Summary\"]:\n",
    "    preprocessed_summary += summary\n",
    "\n",
    "preprocessed_qna = \"\"\n",
    "\n",
    "for qna in earnings_transcript_df[\"Q&A\"]:\n",
    "    preprocessed_qna += qna\n",
    "\n",
    "\n",
    "\n",
    "# Lemmatize the Dataset\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_review(text):\n",
    "    return ' '.join(lemmatizer.lemmatize(w,pos=\"v\") for w in w_tokenizer.tokenize(text))\n",
    "\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].apply(lemmatize_review)\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].astype('string')\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].apply(lemmatize_review)\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].astype('string')\n",
    "print(\"Lemmatize\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e40ca436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8878.595744680852\n",
      "10111.670212765957\n"
     ]
    }
   ],
   "source": [
    "avg_length_summary_after_preprocessing = str(earnings_transcript_df['Summary'].str.len().mean()) \n",
    "avg_length_qna_after_preprocessing = str(earnings_transcript_df['Q&A'].str.len().mean()) \n",
    "print(avg_length_summary_after_preprocessing)\n",
    "print(avg_length_qna_after_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5399804c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Q&amp;A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>incorporate second quarter fy16 earn release c...</td>\n",
       "      <td>first clarification term context 2 billion inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1q16 business review c 1 highlight 1 time reco...</td>\n",
       "      <td>hello much term march quarter guidance imply d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>annotation n p 1 detail 1 instal purchase metr...</td>\n",
       "      <td>much tim little thoughts investments didi inve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>4q16 business review c 1 highlight 1 result se...</td>\n",
       "      <td>afternoon congratulations tim month 7 measurab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Apple</td>\n",
       "      <td>3q17 review c 1 highlight 1 revenue grow produ...</td>\n",
       "      <td>luca first gross margin guidance strong tick j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2020</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>turn call simona jankowski investor relations ...</td>\n",
       "      <td>colette little discussion exactly segment term...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2020</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>turn call simona jankowski vice president inve...</td>\n",
       "      <td>first one strong sequential growth q4 jensen d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2021</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>simona jankowski begin afternoon nvidia call s...</td>\n",
       "      <td>congratulations strong growth execution jensen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2020</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>afternoon nvidia call quarter fiscal 2020 call...</td>\n",
       "      <td>colette jensen speak drive upside quarter infe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2021</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>simona jankowski begin afternoon nvidia call f...</td>\n",
       "      <td>congratulations solid quarter colette commenta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Quarter  Year Company                                            Summary  \\\n",
       "0        Q2  2016   Apple  incorporate second quarter fy16 earn release c...   \n",
       "1        Q1  2016   Apple  1q16 business review c 1 highlight 1 time reco...   \n",
       "2        Q3  2016   Apple  annotation n p 1 detail 1 instal purchase metr...   \n",
       "3        Q4  2016   Apple  4q16 business review c 1 highlight 1 result se...   \n",
       "4        Q3  2017   Apple  3q17 review c 1 highlight 1 revenue grow produ...   \n",
       "..      ...   ...     ...                                                ...   \n",
       "183      Q1  2020  NVIDIA  turn call simona jankowski investor relations ...   \n",
       "184      Q3  2020  NVIDIA  turn call simona jankowski vice president inve...   \n",
       "185      Q2  2021  NVIDIA  simona jankowski begin afternoon nvidia call s...   \n",
       "186      Q4  2020  NVIDIA  afternoon nvidia call quarter fiscal 2020 call...   \n",
       "187      Q1  2021  NVIDIA  simona jankowski begin afternoon nvidia call f...   \n",
       "\n",
       "                                                   Q&A  \n",
       "0    first clarification term context 2 billion inv...  \n",
       "1    hello much term march quarter guidance imply d...  \n",
       "2    much tim little thoughts investments didi inve...  \n",
       "3    afternoon congratulations tim month 7 measurab...  \n",
       "4    luca first gross margin guidance strong tick j...  \n",
       "..                                                 ...  \n",
       "183  colette little discussion exactly segment term...  \n",
       "184  first one strong sequential growth q4 jensen d...  \n",
       "185  congratulations strong growth execution jensen...  \n",
       "186  colette jensen speak drive upside quarter infe...  \n",
       "187  congratulations solid quarter colette commenta...  \n",
       "\n",
       "[188 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earnings_transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a3cc009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running augmentations\n",
    "augdf = earnings_transcript_df.copy()\n",
    "aug = nlpaw.SynonymAug(aug_src='wordnet', model_path=None, name='Synonym_Aug', aug_min=10, aug_max=60, aug_p=0.3)\n",
    "for i in range(len(augdf)):\n",
    "    k = aug.augment(earnings_transcript_df.iloc[i]['Summary'],n=1)\n",
    "    augdf['Summary'][i] = k[0]\n",
    "    k = aug.augment(earnings_transcript_df.iloc[i]['Q&A'],n=1)\n",
    "    augdf['Q&A'][i] = k[0]\n",
    "\n",
    "earnings_transcript_df = earnings_transcript_df.append(augdf)\n",
    "earnings_transcript_df = earnings_transcript_df.reset_index().drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da5be721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Q&amp;A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>incorporate second quarter fy16 earn release c...</td>\n",
       "      <td>first clarification term context 2 billion inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1q16 business review c 1 highlight 1 time reco...</td>\n",
       "      <td>hello much term march quarter guidance imply d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>annotation n p 1 detail 1 instal purchase metr...</td>\n",
       "      <td>much tim little thoughts investments didi inve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>4q16 business review c 1 highlight 1 result se...</td>\n",
       "      <td>afternoon congratulations tim month 7 measurab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Apple</td>\n",
       "      <td>3q17 review c 1 highlight 1 revenue grow produ...</td>\n",
       "      <td>luca first gross margin guidance strong tick j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2020</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>turn call simona jankowski investor relations ...</td>\n",
       "      <td>colette little discussion exactly segment term...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2020</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>turn call simona jankowski vice president inve...</td>\n",
       "      <td>first one strong sequential growth q4 jensen d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2021</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>simona jankowski begin afternoon nvidia call s...</td>\n",
       "      <td>congratulations strong growth execution jensen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2020</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>afternoon nvidia call quarter fiscal 2020 call...</td>\n",
       "      <td>colette jensen speak drive upside quarter infe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2021</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>simona jankowski begin afternoon nvidia call f...</td>\n",
       "      <td>congratulations solid quarter colette commenta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Quarter  Year Company                                            Summary  \\\n",
       "0        Q2  2016   Apple  incorporate second quarter fy16 earn release c...   \n",
       "1        Q1  2016   Apple  1q16 business review c 1 highlight 1 time reco...   \n",
       "2        Q3  2016   Apple  annotation n p 1 detail 1 instal purchase metr...   \n",
       "3        Q4  2016   Apple  4q16 business review c 1 highlight 1 result se...   \n",
       "4        Q3  2017   Apple  3q17 review c 1 highlight 1 revenue grow produ...   \n",
       "..      ...   ...     ...                                                ...   \n",
       "371      Q1  2020  NVIDIA  turn call simona jankowski investor relations ...   \n",
       "372      Q3  2020  NVIDIA  turn call simona jankowski vice president inve...   \n",
       "373      Q2  2021  NVIDIA  simona jankowski begin afternoon nvidia call s...   \n",
       "374      Q4  2020  NVIDIA  afternoon nvidia call quarter fiscal 2020 call...   \n",
       "375      Q1  2021  NVIDIA  simona jankowski begin afternoon nvidia call f...   \n",
       "\n",
       "                                                   Q&A  \n",
       "0    first clarification term context 2 billion inv...  \n",
       "1    hello much term march quarter guidance imply d...  \n",
       "2    much tim little thoughts investments didi inve...  \n",
       "3    afternoon congratulations tim month 7 measurab...  \n",
       "4    luca first gross margin guidance strong tick j...  \n",
       "..                                                 ...  \n",
       "371  colette little discussion exactly segment term...  \n",
       "372  first one strong sequential growth q4 jensen d...  \n",
       "373  congratulations strong growth execution jensen...  \n",
       "374  colette jensen speak drive upside quarter infe...  \n",
       "375  congratulations solid quarter colette commenta...  \n",
       "\n",
       "[376 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earnings_transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31fd4a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>date</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>percent change (between t-2 and t+2)</th>\n",
       "      <th>EPS Surprise</th>\n",
       "      <th>Sentiment_mkt_price</th>\n",
       "      <th>Sentiment_EPS_Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>Q4</td>\n",
       "      <td>2022</td>\n",
       "      <td>10.670590</td>\n",
       "      <td>-16.43</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>2022-08-24</td>\n",
       "      <td>Q3</td>\n",
       "      <td>2022</td>\n",
       "      <td>-28.294456</td>\n",
       "      <td>-59.36</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>Q2</td>\n",
       "      <td>2022</td>\n",
       "      <td>8.816044</td>\n",
       "      <td>5.18</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>Q1</td>\n",
       "      <td>2022</td>\n",
       "      <td>-1.387086</td>\n",
       "      <td>8.02</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>2021-11-17</td>\n",
       "      <td>Q4</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.349566</td>\n",
       "      <td>5.79</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>Q1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.775153</td>\n",
       "      <td>4.93</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2016-10-20</td>\n",
       "      <td>Q4</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.773554</td>\n",
       "      <td>11.27</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>Q3</td>\n",
       "      <td>2016</td>\n",
       "      <td>7.476121</td>\n",
       "      <td>18.76</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>Q2</td>\n",
       "      <td>2016</td>\n",
       "      <td>-7.392503</td>\n",
       "      <td>-2.67</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>Q1</td>\n",
       "      <td>2016</td>\n",
       "      <td>-2.274520</td>\n",
       "      <td>9.40</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Company        date Quarter  Year  \\\n",
       "0       NVIDIA  2022-11-16      Q4  2022   \n",
       "1       NVIDIA  2022-08-24      Q3  2022   \n",
       "2       NVIDIA  2022-05-25      Q2  2022   \n",
       "3       NVIDIA  2022-02-16      Q1  2022   \n",
       "4       NVIDIA  2021-11-17      Q4  2021   \n",
       "..         ...         ...     ...   ...   \n",
       "275  Microsoft  2017-01-26      Q1  2017   \n",
       "276  Microsoft  2016-10-20      Q4  2016   \n",
       "277  Microsoft  2016-07-19      Q3  2016   \n",
       "278  Microsoft  2016-04-21      Q2  2016   \n",
       "279  Microsoft  2016-01-28      Q1  2016   \n",
       "\n",
       "     percent change (between t-2 and t+2)  EPS Surprise Sentiment_mkt_price  \\\n",
       "0                               10.670590        -16.43            Positive   \n",
       "1                              -28.294456        -59.36            Negative   \n",
       "2                                8.816044          5.18            Positive   \n",
       "3                               -1.387086          8.02             Neutral   \n",
       "4                                8.349566          5.79            Positive   \n",
       "..                                    ...           ...                 ...   \n",
       "275                              1.775153          4.93             Neutral   \n",
       "276                              4.773554         11.27            Positive   \n",
       "277                              7.476121         18.76            Positive   \n",
       "278                             -7.392503         -2.67            Negative   \n",
       "279                             -2.274520          9.40             Neutral   \n",
       "\n",
       "    Sentiment_EPS_Surprise  \n",
       "0                 Negative  \n",
       "1                 Negative  \n",
       "2                 Positive  \n",
       "3                 Positive  \n",
       "4                 Positive  \n",
       "..                     ...  \n",
       "275               Positive  \n",
       "276               Positive  \n",
       "277               Positive  \n",
       "278               Negative  \n",
       "279               Positive  \n",
       "\n",
       "[280 rows x 8 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = pd.to_datetime(\"today\")\n",
    "t_days_after = 7\n",
    "t_days_before = 7\n",
    "eps_perc_threshold_for_sentiment = 0.15\n",
    "price_change_perc_threshold_for_sentiment = 3.0\n",
    "# Consolidated Dataframe with sentiments for all companies\n",
    "finance_df = pd.DataFrame(columns=[\"Company\", \"date\", \"Quarter\", \"Year\", \"percent change (between t-2 and t+2)\",\"EPS Surprise\", \"Sentiment_mkt_price\", \"Sentiment_EPS_Surprise\"])\n",
    "\n",
    "company_tickers = ['NVDA','MU','INTC','GOOGL','CSCO','ASML','AMZN','AMD','AAPL','MSFT']\n",
    "\n",
    "\n",
    "\n",
    "for ticker in company_tickers:\n",
    "    \n",
    "    # Get List of dates for Earnings call\n",
    "    ticker_data = yf.Ticker(ticker)\n",
    "    ticker_data.earnings_dates.reset_index(inplace=True)\n",
    "    \n",
    "    #Format Date column\n",
    "    ticker_data.earnings_dates[\"Earnings Date\"] = ticker_data.earnings_dates[\"Earnings Date\"].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    # Filter dates within window of our Transcripts\n",
    "    earnings_dates_df = ticker_data.earnings_dates[(ticker_data.earnings_dates[\"Earnings Date\"]<=today.strftime('%Y-%m-%d')) & (ticker_data.earnings_dates[\"Earnings Date\"]>=\"2015-12-01\")]\n",
    "    earnings_dates_df.loc[:,\"Surprise(%)\"]= earnings_dates_df[\"Surprise(%)\"].apply(lambda x: x*100)\n",
    "    earning_call_dates= earnings_dates_df.iloc[:,0]\n",
    "    earnings_call_surprise = earnings_dates_df.iloc[:,[0,-1]]\n",
    "    #print(ticker)\n",
    "    #print(earnings_call_surprise)\n",
    "    \n",
    "    prepared_df = pd.DataFrame(columns=[\"Company\", \"date\", \"Quarter\", \"Year\", \"percent change (between t-2 and t+2)\",\"EPS Surprise\", \"Sentiment_mkt_price\",\"Sentiment_EPS_Surprise\"])\n",
    "    \n",
    "    historical_data = yf.download(ticker, start=\"2015-11-01\", end=\"2022-11-29\", interval=\"1d\")\n",
    "\n",
    "    historical_data.reset_index(inplace=True)\n",
    "\n",
    "    for date in earning_call_dates:\n",
    "        # Compute Quarters for each date to join finance df with Transcripts DF created in above cells\n",
    "        month=pd.to_datetime(date).month\n",
    "        year=pd.to_datetime(date).year\n",
    "        if month<=3:\n",
    "            quarter=\"Q1\"\n",
    "        elif month<=6:\n",
    "            quarter=\"Q2\"\n",
    "        elif month<=9:\n",
    "            quarter=\"Q3\"\n",
    "        else:\n",
    "            quarter=\"Q4\"\n",
    "                \n",
    "        # Compute % change by looking at T-2 and T+2 window from earnings call date\n",
    "        # i.e. if Earnings call is 27 Oct 2022 => compute:\n",
    "        # => (Closing_price['29 Oct'] - Closing_price['27 Oct']) * 100 / (Closing_price['27 Oct'])\n",
    "        \n",
    "        index= historical_data.index[historical_data[\"Date\"]==pd.to_datetime(date)]\n",
    "        closing_price_after_earnings_call = float(historical_data.loc[index+t_days_after,\"Adj Close\"])\n",
    "        closing_price_before_earnings_call = float(historical_data.loc[index-t_days_before,\"Adj Close\"])\n",
    "        change = (closing_price_after_earnings_call - closing_price_before_earnings_call)*100/closing_price_before_earnings_call\n",
    "        eps_surprise = float(earnings_call_surprise[earnings_call_surprise[\"Earnings Date\"] == date][\"Surprise(%)\"])\n",
    "        #print(earnings_call_surprise[earnings_call_surprise[\"Earnings Date\"] == date, \"Surprise(%)\"])\n",
    "        # Computer sentiment based on price change percentage threshold\n",
    "        if abs(change)<= price_change_perc_threshold_for_sentiment:\n",
    "            label_mkt_price=\"Neutral\"\n",
    "        elif change> price_change_perc_threshold_for_sentiment:\n",
    "            label_mkt_price=\"Positive\"\n",
    "        else:\n",
    "            label_mkt_price=\"Negative\"\n",
    "            \n",
    "        if abs(eps_surprise - 1.0)<= eps_perc_threshold_for_sentiment:\n",
    "            label_eps=\"Neutral\"\n",
    "        elif (eps_surprise)> 1.0 + eps_perc_threshold_for_sentiment:\n",
    "            label_eps=\"Positive\"\n",
    "        else:\n",
    "            label_eps=\"Negative\"   \n",
    "        prepared_df = prepared_df.append({\"Company\":companies[ticker],\"date\":date,\"Quarter\":quarter, \"Year\": year, \"percent change (between t-2 and t+2)\": change,\"EPS Surprise\": eps_surprise, \"Sentiment_mkt_price\": label_mkt_price, \"Sentiment_EPS_Surprise\":label_eps}, ignore_index=True)\n",
    "    prepared_df.reset_index(drop=True)\n",
    "    prepared_df.to_csv(\"..\\\\data\\\\OHLC\\\\\"+ticker+\".csv\", encoding='utf-8')\n",
    "    finance_df=pd.concat([finance_df, prepared_df], ignore_index=True)\n",
    "finance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4e298eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_df.Year = finance_df.Year.astype('int')\n",
    "earnings_transcript_df.Year = earnings_transcript_df.Year.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68dc675a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merged = pd.merge(earnings_transcript_df, finance_df, on=['Company', 'Year', 'Quarter'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6fa9fc0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Q&amp;A</th>\n",
       "      <th>date</th>\n",
       "      <th>percent change (between t-2 and t+2)</th>\n",
       "      <th>EPS Surprise</th>\n",
       "      <th>Sentiment_mkt_price</th>\n",
       "      <th>Sentiment_EPS_Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>incorporate second quarter fy16 earn release c...</td>\n",
       "      <td>first clarification term context 2 billion inv...</td>\n",
       "      <td>2016-04-26</td>\n",
       "      <td>-14.603822</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>incorporate second quarter fy16 earn release o...</td>\n",
       "      <td>first clarification term context 2 billion inv...</td>\n",
       "      <td>2016-04-26</td>\n",
       "      <td>-14.603822</td>\n",
       "      <td>-4.90</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1q16 business review c 1 highlight 1 time reco...</td>\n",
       "      <td>hello much term march quarter guidance imply d...</td>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>-2.407392</td>\n",
       "      <td>1.64</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1q16 business review c 1 highlight 1 time reco...</td>\n",
       "      <td>hello much term march quarter guidance imply d...</td>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>-2.407392</td>\n",
       "      <td>1.64</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>annotation n p 1 detail 1 instal purchase metr...</td>\n",
       "      <td>much tim little thoughts investments didi inve...</td>\n",
       "      <td>2016-07-26</td>\n",
       "      <td>7.758173</td>\n",
       "      <td>2.60</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2021</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>simona jankowski begin afternoon nvidia call s...</td>\n",
       "      <td>congratulations strong growth execution jensen...</td>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>24.379663</td>\n",
       "      <td>11.45</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2020</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>afternoon nvidia call quarter fiscal 2020 call...</td>\n",
       "      <td>colette jensen speak drive upside quarter infe...</td>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>-1.681848</td>\n",
       "      <td>13.22</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2020</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>afternoon nvidia call quarter fiscal 2020 call...</td>\n",
       "      <td>colette jensen speak drive upside quarter infe...</td>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>-1.681848</td>\n",
       "      <td>13.22</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2021</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>simona jankowski begin afternoon nvidia call f...</td>\n",
       "      <td>congratulations solid quarter colette commenta...</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>-16.708161</td>\n",
       "      <td>10.40</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2021</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>simona jankowski begin afternoon nvidia call f...</td>\n",
       "      <td>congratulations solid quarter colette commenta...</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>-16.708161</td>\n",
       "      <td>10.40</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Quarter  Year Company                                            Summary  \\\n",
       "0        Q2  2016   Apple  incorporate second quarter fy16 earn release c...   \n",
       "1        Q2  2016   Apple  incorporate second quarter fy16 earn release o...   \n",
       "2        Q1  2016   Apple  1q16 business review c 1 highlight 1 time reco...   \n",
       "3        Q1  2016   Apple  1q16 business review c 1 highlight 1 time reco...   \n",
       "4        Q3  2016   Apple  annotation n p 1 detail 1 instal purchase metr...   \n",
       "..      ...   ...     ...                                                ...   \n",
       "361      Q2  2021  NVIDIA  simona jankowski begin afternoon nvidia call s...   \n",
       "362      Q4  2020  NVIDIA  afternoon nvidia call quarter fiscal 2020 call...   \n",
       "363      Q4  2020  NVIDIA  afternoon nvidia call quarter fiscal 2020 call...   \n",
       "364      Q1  2021  NVIDIA  simona jankowski begin afternoon nvidia call f...   \n",
       "365      Q1  2021  NVIDIA  simona jankowski begin afternoon nvidia call f...   \n",
       "\n",
       "                                                   Q&A        date  \\\n",
       "0    first clarification term context 2 billion inv...  2016-04-26   \n",
       "1    first clarification term context 2 billion inv...  2016-04-26   \n",
       "2    hello much term march quarter guidance imply d...  2016-01-26   \n",
       "3    hello much term march quarter guidance imply d...  2016-01-26   \n",
       "4    much tim little thoughts investments didi inve...  2016-07-26   \n",
       "..                                                 ...         ...   \n",
       "361  congratulations strong growth execution jensen...  2021-05-26   \n",
       "362  colette jensen speak drive upside quarter infe...  2020-11-18   \n",
       "363  colette jensen speak drive upside quarter infe...  2020-11-18   \n",
       "364  congratulations solid quarter colette commenta...  2021-02-24   \n",
       "365  congratulations solid quarter colette commenta...  2021-02-24   \n",
       "\n",
       "     percent change (between t-2 and t+2)  EPS Surprise Sentiment_mkt_price  \\\n",
       "0                              -14.603822         -4.90            Negative   \n",
       "1                              -14.603822         -4.90            Negative   \n",
       "2                               -2.407392          1.64             Neutral   \n",
       "3                               -2.407392          1.64             Neutral   \n",
       "4                                7.758173          2.60            Positive   \n",
       "..                                    ...           ...                 ...   \n",
       "361                             24.379663         11.45            Positive   \n",
       "362                             -1.681848         13.22             Neutral   \n",
       "363                             -1.681848         13.22             Neutral   \n",
       "364                            -16.708161         10.40            Negative   \n",
       "365                            -16.708161         10.40            Negative   \n",
       "\n",
       "    Sentiment_EPS_Surprise  \n",
       "0                 Negative  \n",
       "1                 Negative  \n",
       "2                 Positive  \n",
       "3                 Positive  \n",
       "4                 Positive  \n",
       "..                     ...  \n",
       "361               Positive  \n",
       "362               Positive  \n",
       "363               Positive  \n",
       "364               Positive  \n",
       "365               Positive  \n",
       "\n",
       "[366 rows x 10 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7b3f7a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.16.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c61cd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_y = df_merged[['Summary','Sentiment_EPS_Surprise']].sample(frac = 0.80, random_state = 42)\n",
    "test_x_y = pd.concat([df_merged[['Summary','Sentiment_EPS_Surprise']], train_x_y]).drop_duplicates(keep=False)\n",
    "train_x_y[\"Sentiment_EPS_Surprise\"] = le.fit_transform(train_x_y[\"Sentiment_EPS_Surprise\"])\n",
    "test_x_y[\"Sentiment_EPS_Surprise\"] = le.fit_transform(test_x_y[\"Sentiment_EPS_Surprise\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "375ff2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment_EPS_Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentiment_EPS_Surprise\n",
       "0                 Negative\n",
       "1                 Negative\n",
       "2                 Positive\n",
       "3                 Positive\n",
       "4                 Positive\n",
       "..                     ...\n",
       "361               Positive\n",
       "362               Positive\n",
       "363               Positive\n",
       "364               Positive\n",
       "365               Positive\n",
       "\n",
       "[366 rows x 1 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_merged[['Summary']]\n",
    "Y = df_merged[['Sentiment_EPS_Surprise']]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b2902727",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42, shuffle=True, stratify=Y)\n",
    "train_x_y = pd.concat([x_train, y_train], axis=1,  names=['Summary', 'Sentiment_EPS_Surprise'])\n",
    "test_x_y = pd.concat([x_test, y_test], axis=1, names=['Summary', 'Sentiment_EPS_Surprise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aa0edff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245, 2)\n",
      "(121, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_x_y.shape)\n",
    "print(test_x_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3beb4772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment_EPS_Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>introduce marilyn mora head investor relations...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>technical trouble veldhoven netherlands asml c...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>turn call mr skip miller ahead sir skip mornin...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>turn call director investor relations dave fil...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>turn call arnab chanda vice president investor...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>turn host mr mike spencer manager investor rel...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>turn mr craig deyoung ahead sir patricia after...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>hand loudspeaker system ellen west head invest...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>turn ellen west head investor relations ahead ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>ladies gentlemen intel corporation q1 earn cal...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Summary Sentiment_EPS_Surprise\n",
       "164  introduce marilyn mora head investor relations...                Neutral\n",
       "139  technical trouble veldhoven netherlands asml c...               Positive\n",
       "132  turn call mr skip miller ahead sir skip mornin...               Positive\n",
       "88   turn call director investor relations dave fil...               Positive\n",
       "334  turn call arnab chanda vice president investor...               Positive\n",
       "..                                                 ...                    ...\n",
       "288  turn host mr mike spencer manager investor rel...               Positive\n",
       "115  turn mr craig deyoung ahead sir patricia after...               Positive\n",
       "217  hand loudspeaker system ellen west head invest...               Negative\n",
       "200  turn ellen west head investor relations ahead ...               Positive\n",
       "220  ladies gentlemen intel corporation q1 earn cal...               Positive\n",
       "\n",
       "[121 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "18603518",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_y[\"Sentiment_EPS_Surprise\"] = le.fit_transform(train_x_y[\"Sentiment_EPS_Surprise\"])\n",
    "test_x_y[\"Sentiment_EPS_Surprise\"] = le.fit_transform(test_x_y[\"Sentiment_EPS_Surprise\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a854c1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment_EPS_Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>michelle cisco quarter fiscal 2020 quarterly e...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>ladies gentlemen alphabet quarter earn call af...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>turn call ms shanye hudson madam begin chelsea...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2q20 review c 1 overview 1 revenue 58 3b 1 tim...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>turn call mr skip miller ahead sir operator sk...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>hello q3 financial result shout join olsavsky ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>afternoon join call satya nadella chief execut...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>turn call simona jankowski vice president inve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>hello q4 fiscal consequence call option join o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>hand host head investor relations farhan ahmad...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Summary  Sentiment_EPS_Surprise\n",
       "183  michelle cisco quarter fiscal 2020 quarterly e...                       2\n",
       "192  ladies gentlemen alphabet quarter earn call af...                       2\n",
       "303  turn call ms shanye hudson madam begin chelsea...                       2\n",
       "33   2q20 review c 1 overview 1 revenue 58 3b 1 tim...                       2\n",
       "140  turn call mr skip miller ahead sir operator sk...                       2\n",
       "..                                                 ...                     ...\n",
       "103  hello q3 financial result shout join olsavsky ...                       0\n",
       "282  afternoon join call satya nadella chief execut...                       2\n",
       "346  turn call simona jankowski vice president inve...                       0\n",
       "99   hello q4 fiscal consequence call option join o...                       2\n",
       "316  hand host head investor relations farhan ahmad...                       2\n",
       "\n",
       "[245 rows x 2 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5c842f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "model_args = ClassificationArgs()\n",
    "model_args.train_batch_size = 2\n",
    "model_args.gradient_accumulation_steps = 10\n",
    "model_args.learning_rate = 3e-4\n",
    "model_args.num_train_epochs = 6\n",
    "model_args.overwrite_output_dir=True\n",
    "model_bert = ClassificationModel(\"bert\", \"bert-base-uncased\", num_labels=3, args=model_args, use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e61aac0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022066354751586914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 245,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab91d0ee53e540c59e611b728471198d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013997077941894531,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Epoch",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be39eba905d841e6ab5c6a7661148ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014000415802001953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Running Epoch 0 of 2",
       "rate": null,
       "total": 123,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860f6c41d028426eb63cc34ad62c7137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010509729385375977,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Running Epoch 1 of 2",
       "rate": null,
       "total": 123,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3d397d67844fc0bc6491448e988b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 2:   0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(30, 0.6761158640806874)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bert.train_model(train_x_y, overwrite_output_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f2d36bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03124856948852539,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 121,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39152568926740869205c9b5872b7999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016001462936401367,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 16,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb803d01a4947b2992c139d25b447d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score --> 0.8181818181818182\n",
      "F1 score --> 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "pred_bert, out_bert = model_bert.predict(list(test_x_y['Summary'].values))\n",
    "\n",
    "acc_bert = accuracy_score(test_x_y['Sentiment_EPS_Surprise'].to_numpy(), pred_bert)\n",
    "f1_bert = f1_score(test_x_y['Sentiment_EPS_Surprise'].to_numpy(), pred_bert, average='micro')\n",
    "\n",
    "print(\"Accuracy score -->\", acc_bert)\n",
    "print(\"F1 score -->\", f1_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62970933",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8d4c5e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164    1\n",
       "139    2\n",
       "132    2\n",
       "88     2\n",
       "334    2\n",
       "      ..\n",
       "288    2\n",
       "115    2\n",
       "217    0\n",
       "200    2\n",
       "220    2\n",
       "Name: Sentiment_EPS_Surprise, Length: 121, dtype: int32"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_y['Sentiment_EPS_Surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "aa290006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = precision_score(pred_bert, test_x_y['Sentiment_EPS_Surprise'].to_numpy(), average='micro')\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "899639b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = recall_score(pred_bert, test_x_y['Sentiment_EPS_Surprise'].to_numpy(), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0580fae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea7faa9",
   "metadata": {},
   "source": [
    "## REFERENCES\n",
    "https://www.kaggle.com/code/kamalkhumar/financial-news-analysis-using-bert-with-eda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
