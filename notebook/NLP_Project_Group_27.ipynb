{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "\n",
    "\n",
    "import contractions\n",
    "import os\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# from transformers import BertForSequenceClassification, BertTokenizer\n",
    "# import torch\n",
    "\n",
    "# from torch.utils.data.sampler import SubsetRandomSampler\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# cuda = torch.device('cuda')\n",
    "\n",
    "\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nlpaug\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "!pip install yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0468b11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/Transcripts'\n",
    "df = pd.DataFrame()\n",
    "companies = {'AMZN':'Amazon',\n",
    " 'AAPL':'Apple',\n",
    " 'INTC':'Intel',\n",
    " 'MU':'Micron',\n",
    " 'GOOGL': 'Alphabet',\n",
    " 'MSFT': 'Microsoft',\n",
    " 'AMD':'AMD',\n",
    " 'ASML':'ASML',\n",
    " 'NVDA':'NVIDIA',\n",
    " 'CSCO':'Cisco'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acae6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "tf = 0\n",
    "totalsummary = ''\n",
    "totalqna = ''\n",
    "for comp in os.listdir(path):\n",
    "    if comp!='.DS_Store':\n",
    "        company = comp\n",
    "        files = os.listdir(path+'/'+company)\n",
    "        for j in files:\n",
    "            allinfo = []\n",
    "            with open(path+'/'+company+'/'+j) as f:\n",
    "                lines = f.readlines()\n",
    "                summary = []\n",
    "                qna = []\n",
    "                i = 0\n",
    "                while i<len(lines):\n",
    "                    if lines[i]=='\\n':\n",
    "                        i+=1\n",
    "                    elif lines[i][:3]=='===':\n",
    "                        i+=1\n",
    "                    elif 'operator' in lines[i].lower():\n",
    "                        i+=3\n",
    "                    elif lines[i][:3] == '---':\n",
    "                        i+=1\n",
    "                    elif 'presentation' in lines[i].lower():\n",
    "                        i+=2\n",
    "#                         print(j)\n",
    "                        while i<len(lines):\n",
    "#                             print(lines[i])\n",
    "                            if '===' in lines[i]:\n",
    "                                break\n",
    "                            if 'Questions and Answers' in lines[i]:\n",
    "                                break\n",
    "                            elif lines[i]=='\\n':\n",
    "                                i+=1\n",
    "                                continue\n",
    "                            elif 'operator' in lines[i].lower():\n",
    "                                i+=3\n",
    "                            elif '---' in lines[i]:\n",
    "                                i+=1\n",
    "                            summary.append(lines[i].rstrip())\n",
    "                            i+=1\n",
    "                    \n",
    "                    elif '[' in lines[i] and companies[company].lower() in lines[i].lower():\n",
    "                        i+=2\n",
    "                        while lines[i][:3]!='---':\n",
    "                            if lines[i]=='\\n':\n",
    "                                i+=1\n",
    "                                continue\n",
    "                            summary.append(lines[i].rstrip())\n",
    "                            i+=1\n",
    "                    \n",
    "                    elif 'Questions and Answers' in lines[i]:\n",
    "                        i+=1\n",
    "                        while i<len(lines):\n",
    "                            if lines[i]=='\\n':\n",
    "                                i+=1\n",
    "                            elif 'Operator' in lines[i]:\n",
    "                                i+=2\n",
    "                            elif lines[i][:3] == '---':\n",
    "                                i+=1\n",
    "                            elif '[' in lines[i]:\n",
    "                                i+=2\n",
    "                            else:\n",
    "                                qna.append(lines[i].rstrip())\n",
    "                                i+=1\n",
    "                    \n",
    "                    elif '[' in lines[i] and companies[company].lower() not in lines[i].lower():\n",
    "                        while i<len(lines):\n",
    "                            if lines[i]=='\\n':\n",
    "                                i+=1\n",
    "                            elif 'Operator' in lines[i]:\n",
    "                                i+=3\n",
    "                            elif lines[i][:3] == '---':\n",
    "                                i+=1\n",
    "                            elif '[' in lines[i]:\n",
    "                                i+=2\n",
    "                            else:\n",
    "                                qna.append(lines[i].rstrip())\n",
    "                                i+=1\n",
    "                    else:\n",
    "                        i+=1\n",
    "                \n",
    "                if lines[0][0] == 'Q':\n",
    "                    quarter = lines[0].split(' ')[0]\n",
    "                    year = lines[0].split(' ')[1]\n",
    "                else:\n",
    "                    quarter = lines[1].split(' ')[0]\n",
    "                    year = lines[1].split(' ')[1]\n",
    "                cleansummary = []\n",
    "#                 print(j)\n",
    "                for i in range(len(summary)):\n",
    "                    if '--' in summary[i]:\n",
    "                        i+=1\n",
    "                    elif 'Operator' in summary[i]:\n",
    "                        i+=3\n",
    "                    elif '[' in summary[i]:\n",
    "#                         print(i, summary[i])\n",
    "                        i+=1\n",
    "                    else:\n",
    "                        cleansummary.append(summary[i])\n",
    "                summary_para = ' '.join(cleansummary).rstrip()\n",
    "                qna_para = ' '.join(qna).rstrip()\n",
    "                totalsummary += summary_para\n",
    "                totalqna = qna_para\n",
    "                allinfo.append(quarter)\n",
    "                allinfo.append(year)\n",
    "                allinfo.append(companies[company])\n",
    "                allinfo.append(summary_para)\n",
    "                allinfo.append(qna_para)\n",
    "                df.append(allinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_transcript_df = pd.DataFrame(df)\n",
    "earnings_transcript_df.columns =['Quarter','Year','Company','Summary','Q&A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781bd569",
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f844d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = Counter(totalsummary.split(' '))\n",
    "words += Counter(totalqna.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57258f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from readability import Readability\n",
    "r = Readability(earnings_transcript_df.iloc[0,3])\n",
    "r.flesch_kincaid()\n",
    "print(r.flesch())\n",
    "print(r.gunning_fog())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708dae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgTxtLen(df):\n",
    "    avg_length_summary_after_preprocessing = str(df['Summary'].str.len().mean()) \n",
    "    avg_length_qna_after_preprocessing = str(df['Q&A'].str.len().mean()) \n",
    "    print(avg_length_summary_after_preprocessing)\n",
    "    print(avg_length_qna_after_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0412dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(text): \n",
    "    soup = BeautifulSoup(text, \"html.parser\") \n",
    "    stripped_text = soup.get_text(separator=\" \") \n",
    "    return stripped_text \n",
    "    \n",
    "# Make lowercase\n",
    "earnings_transcript_df[\"Summary\"] = earnings_transcript_df[\"Summary\"].str.lower()\n",
    "earnings_transcript_df[\"Q&A\"] = earnings_transcript_df[\"Q&A\"].str.lower()\n",
    "\n",
    "# Remove URLS\n",
    "earnings_transcript_df['Summary']= earnings_transcript_df['Summary'].str.replace('http(s)?:\\/\\/.*', '', regex=True)\n",
    "earnings_transcript_df['Q&A']= earnings_transcript_df['Q&A'].str.replace('http(s)?:\\/\\/.*', '', regex=True)\n",
    "print(\"Remove URLS\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# remove HTML tags\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].apply(lambda x: strip_html_tags(x))\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].apply(lambda x: strip_html_tags(x))\n",
    "print(\"remove HTML tags\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# remove extra whitespaces\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].replace(r'/\\s/\\s+/g', ' ', regex=True)\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].replace(r'/\\s/\\s+/g', ' ', regex=True)\n",
    "print(\"remove extra whitespaces\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# remove contractions\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].apply(lambda x: ' '.join([contractions.fix(word) for word in x.split()]))\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].apply(lambda x: ' '.join([contractions.fix(word) for word in x.split()]))\n",
    "print(\"remove contractions\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# Remove characters following digits such as 1st, 2nd or 3rd\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].str.replace('\\b\\d+\\w+\\b', '', regex=True)\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].str.replace('\\b\\d+\\w+\\b', '', regex=True)\n",
    "print(\"Remove characters following digits such as 1st, 2nd or 3rd\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# Replace hyphens with space\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].replace('/\\b-\\b/g', ' ', regex=True)\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].replace('/\\b-\\b/g', ' ', regex=True)\n",
    "print(\"Replace hyphens with space\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# remove non alphabetical characters\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].str.replace('[^a-zA-Z0-9 ]', ' ')\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].str.replace('[^a-zA-Z0-9 ]', ' ')\n",
    "print(\"remove non alphabetical characters\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aec14a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_transcript_df.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180dc732",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words) ]))\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].astype('string')\n",
    "\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words) ]))\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].astype('string')\n",
    "\n",
    "print(\"Stopwords\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "# Lemmatize the Dataset\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_review(text):\n",
    "    return ' '.join(lemmatizer.lemmatize(w,pos=\"v\") for w in w_tokenizer.tokenize(text))\n",
    "\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].apply(lemmatize_review)\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].astype('string')\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].apply(lemmatize_review)\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].astype('string')\n",
    "print(\"Lemmatize\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40ca436",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_length_summary_after_preprocessing = str(earnings_transcript_df['Summary'].str.len().mean()) \n",
    "avg_length_qna_after_preprocessing = str(earnings_transcript_df['Q&A'].str.len().mean()) \n",
    "print(avg_length_summary_after_preprocessing)\n",
    "print(avg_length_qna_after_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3cc009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running augmentations\n",
    "augdf = earnings_transcript_df.copy()\n",
    "aug = naw.SynonymAug(aug_src='wordnet', model_path=None, name='Synonym_Aug', aug_min=10, aug_max=60, aug_p=0.3)\n",
    "for i in range(len(augdf)):\n",
    "    k = aug.augment(earnings_transcript_df.iloc[i]['Summary'],n=1)\n",
    "    augdf['Summary'][i] = k[0]\n",
    "    k = aug.augment(earnings_transcript_df.iloc[i]['Q&A'],n=1)\n",
    "    augdf['Q&A'][i] = k[0]\n",
    "\n",
    "earnings_transcript_df = earnings_transcript_df.append(augdf)\n",
    "earnings_transcript_df = earnings_transcript_df.reset_index().drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5be721",
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fd4a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = pd.to_datetime(\"today\")\n",
    "\n",
    "# Consolidated Dataframe with sentiments for all companies\n",
    "finance_df = pd.DataFrame(columns=[\"Company\", \"date\", \"Quarter\", \"Year\", \"percent change (between t-2 and t+2)\",\"Sentiment\"])\n",
    "\n",
    "company_tickers = ['NVDA','MU','INTC','GOOGL','CSCO','ASML','AMZN','AMD','AAPL','MSFT']\n",
    "\n",
    "price_change_perc_threshold_for_sentiment = 3.0\n",
    "\n",
    "for ticker in company_tickers:\n",
    "    \n",
    "    # Get List of dates for Earnings call\n",
    "    ticker_data = yf.Ticker(ticker)\n",
    "    ticker_data.earnings_dates.reset_index(inplace=True)\n",
    "    \n",
    "    #Format Date column\n",
    "    ticker_data.earnings_dates[\"Earnings Date\"] = ticker_data.earnings_dates[\"Earnings Date\"].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    # Filter dates within window of our Transcripts\n",
    "    earnings_dates_df = ticker_data.earnings_dates[(ticker_data.earnings_dates[\"Earnings Date\"]<=today.strftime('%Y-%m-%d')) & (ticker_data.earnings_dates[\"Earnings Date\"]>=\"2015-12-01\")]\n",
    "    earning_call_dates= earnings_dates_df.iloc[:,0]\n",
    "\n",
    "    #print(earning_call_dates)\n",
    "    \n",
    "    prepared_df = pd.DataFrame(columns=[\"Company\", \"date\", \"Quarter\", \"Year\", \"percent change (between t-2 and t+2)\",\"Sentiment\"])\n",
    "    \n",
    "    historical_data = yf.download(ticker, start=\"2015-12-01\", end=\"2022-11-21\", interval=\"1d\")\n",
    "\n",
    "    historical_data.reset_index(inplace=True)\n",
    "\n",
    "    for date in earning_call_dates:\n",
    "        # Compute Quarters for each date to join finance df with Transcripts DF created in above cells\n",
    "        month=pd.to_datetime(date).month\n",
    "        year=pd.to_datetime(date).year\n",
    "        if month<=3:\n",
    "            quarter=\"Q1\"\n",
    "        elif month<=6:\n",
    "            quarter=\"Q2\"\n",
    "        elif month<=9:\n",
    "            quarter=\"Q3\"\n",
    "        else:\n",
    "            quarter=\"Q4\"\n",
    "                \n",
    "        # Compute % change by looking at T-2 and T+2 window from earnings call date\n",
    "        # i.e. if Earnings call is 27 Oct 2022 => compute:\n",
    "        # => (Closing_price['29 Oct'] - Closing_price['27 Oct']) * 100 / (Closing_price['27 Oct'])\n",
    "        \n",
    "        index= historical_data.index[historical_data[\"Date\"]==pd.to_datetime(date)]\n",
    "        tplus2= float(historical_data.loc[index+2,\"Adj Close\"])\n",
    "        tminus2 = float(historical_data.loc[index-2,\"Adj Close\"])\n",
    "        change = (tplus2 - tminus2)*100/tminus2\n",
    "        \n",
    "        # Computer sentiment based on price change percentage threshold\n",
    "        if abs(change)< price_change_perc_threshold_for_sentiment:\n",
    "            label=\"Neutral\"\n",
    "        elif change> price_change_perc_threshold_for_sentiment:\n",
    "            label=\"Positive\"\n",
    "        else:\n",
    "            label=\"Negative\"\n",
    "        prepared_df = prepared_df.append({\"Company\":companies[ticker],\"date\":date,\"Quarter\":quarter, \"Year\": year, \"percent change (between t-2 and t+2)\": change, \"Sentiment\": label}, ignore_index=True)\n",
    "    prepared_df.reset_index(drop=True)\n",
    "    prepared_df.to_csv(\"..\\\\data\\\\OHLC\\\\\"+ticker+\".csv\", encoding='utf-8')\n",
    "    finance_df=pd.concat([finance_df, prepared_df], ignore_index=True)\n",
    "finance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e298eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_df.Year = finance_df.Year.astype('int')\n",
    "earnings_transcript_df.Year = earnings_transcript_df.Year.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc675a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merged = pd.merge(earnings_transcript_df, finance_df, on=['Company', 'Year', 'Quarter'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa9fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f7a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing  import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import missingno as miss\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.offline import iplot\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk.corpus import stopwords    \n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, SpatialDropout1D, MaxPooling1D, Conv1D, Concatenate, Bidirectional, GlobalMaxPool1D, ActivityRegularization, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61cd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_y = df_merged[['Q&A','Sentiment']].sample(frac = 0.80, random_state = 42)\n",
    "test_x_y = pd.concat([df_merged[['Q&A','Sentiment']], train_x_y]).drop_duplicates(keep=False)\n",
    "train_x_y[\"Sentiment\"] = le.fit_transform(train_x_y[\"Sentiment\"])\n",
    "test_x_y[\"Sentiment\"] = le.fit_transform(test_x_y[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0edff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x_y.shape)\n",
    "print(test_x_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c842f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "\n",
    "model_args = ClassificationArgs()\n",
    "model_args.train_batch_size = 2\n",
    "model_args.gradient_accumulation_steps = 8\n",
    "model_args.learning_rate = 3e-5\n",
    "model_args.num_train_epochs = 1\n",
    "\n",
    "model_bert = ClassificationModel(\"bert\", \"bert-base-uncased\", num_labels=3, args=model_args, use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61aac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bert.train_model(train_x_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d36bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bert, out_bert = model_bert.predict(list(test_x_y['Q&A'].values))\n",
    "\n",
    "acc_bert = accuracy_score(test_x_y['Sentiment'].to_numpy(), pred_bert)\n",
    "f1_bert = f1_score(test_x_y['Sentiment'].to_numpy(), pred_bert, average='micro')\n",
    "\n",
    "print(\"Accuracy score -->\", acc_bert)\n",
    "print(\"F1 score -->\", f1_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(pred_bert, test_x_y['Sentiment'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb6c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(pred_bert, test_x_y['Sentiment'].to_numpy(), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c379944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = recall_score(pred_bert, test_x_y['Sentiment'].to_numpy(), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be78f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd80206",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f0234e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
