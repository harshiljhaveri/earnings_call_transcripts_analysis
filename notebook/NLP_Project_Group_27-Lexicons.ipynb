{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5934b256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jaimansukhani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in /opt/miniconda3/lib/python3.9/site-packages (0.1.87)\n",
      "Requirement already satisfied: lxml>=4.5.1 in /opt/miniconda3/lib/python3.9/site-packages (from yfinance) (4.8.0)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in /opt/miniconda3/lib/python3.9/site-packages (from yfinance) (1.4.4)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /opt/miniconda3/lib/python3.9/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/miniconda3/lib/python3.9/site-packages (from yfinance) (1.4.0)\n",
      "Requirement already satisfied: requests>=2.26 in /opt/miniconda3/lib/python3.9/site-packages (from yfinance) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/miniconda3/lib/python3.9/site-packages (from yfinance) (1.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/miniconda3/lib/python3.9/site-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.9/site-packages (from pandas>=0.24.0->yfinance) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=0.24.0->yfinance) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.9/site-packages (from requests>=2.26->yfinance) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.9/site-packages (from requests>=2.26->yfinance) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/miniconda3/lib/python3.9/site-packages (from requests>=2.26->yfinance) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda3/lib/python3.9/site-packages (from requests>=2.26->yfinance) (1.26.8)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/opt/miniconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "\n",
    "\n",
    "import contractions\n",
    "import os\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "cuda = torch.device('cuda')\n",
    "\n",
    "\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "!pip install yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch\n",
    "\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "import nlpaug\n",
    "import nlpaug.augmenter.word as naw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fa0e714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /opt/miniconda3/lib/python3.9/site-packages (0.1.72)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /opt/miniconda3/lib/python3.9/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: pyahocorasick in /opt/miniconda3/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
      "Requirement already satisfied: anyascii in /opt/miniconda3/lib/python3.9/site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/opt/miniconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77c78758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "067d8823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jaimansukhani/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jaimansukhani/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jaimansukhani/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/jaimansukhani/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jaimansukhani/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/jaimansukhani/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe3fd526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cab3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/Transcripts'\n",
    "df = pd.DataFrame()\n",
    "companies = {'AMZN':'Amazon',\n",
    " 'AAPL':'Apple',\n",
    " 'INTC':'Intel',\n",
    " 'MU':'Micron',\n",
    " 'GOOGL': 'Alphabet',\n",
    " 'MSFT': 'Microsoft',\n",
    " 'AMD':'AMD',\n",
    " 'ASML':'ASML',\n",
    " 'NVDA':'NVIDIA',\n",
    " 'CSCO':'Cisco'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0acae6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "tf = 0\n",
    "totalsummary = ''\n",
    "totalqna = ''\n",
    "for comp in os.listdir(path):\n",
    "    if comp!='.DS_Store':\n",
    "        company = comp\n",
    "        files = os.listdir(path+'/'+company)\n",
    "        for j in files:\n",
    "            allinfo = []\n",
    "            with open(path+'/'+company+'/'+j) as f:\n",
    "                lines = f.readlines()\n",
    "                summary = []\n",
    "                qna = []\n",
    "                i = 0\n",
    "                while i<len(lines):\n",
    "                    if lines[i]=='\\n':\n",
    "                        i+=1\n",
    "                    elif lines[i][:3]=='===':\n",
    "                        i+=1\n",
    "                    elif 'operator' in lines[i].lower():\n",
    "                        i+=3\n",
    "                    elif lines[i][:3] == '---':\n",
    "                        i+=1\n",
    "                    elif 'presentation' in lines[i].lower():\n",
    "                        i+=2\n",
    "#                         print(j)\n",
    "                        while i<len(lines):\n",
    "#                             print(lines[i])\n",
    "                            if '===' in lines[i]:\n",
    "                                break\n",
    "                            if 'Questions and Answers' in lines[i]:\n",
    "                                break\n",
    "                            elif lines[i]=='\\n':\n",
    "                                i+=1\n",
    "                                continue\n",
    "                            elif 'operator' in lines[i].lower():\n",
    "                                i+=3\n",
    "                            elif '---' in lines[i]:\n",
    "                                i+=1\n",
    "                            summary.append(lines[i].rstrip())\n",
    "                            i+=1\n",
    "                    \n",
    "                    elif '[' in lines[i] and companies[company].lower() in lines[i].lower():\n",
    "                        i+=2\n",
    "                        while lines[i][:3]!='---':\n",
    "                            if lines[i]=='\\n':\n",
    "                                i+=1\n",
    "                                continue\n",
    "                            summary.append(lines[i].rstrip())\n",
    "                            i+=1\n",
    "                    \n",
    "                    elif 'Questions and Answers' in lines[i]:\n",
    "                        i+=1\n",
    "                        while i<len(lines):\n",
    "                            if lines[i]=='\\n':\n",
    "                                i+=1\n",
    "                            elif 'Operator' in lines[i]:\n",
    "                                i+=2\n",
    "                            elif lines[i][:3] == '---':\n",
    "                                i+=1\n",
    "                            elif '[' in lines[i]:\n",
    "                                i+=2\n",
    "                            else:\n",
    "                                qna.append(lines[i].rstrip())\n",
    "                                i+=1\n",
    "                    \n",
    "                    elif '[' in lines[i] and companies[company].lower() not in lines[i].lower():\n",
    "                        while i<len(lines):\n",
    "                            if lines[i]=='\\n':\n",
    "                                i+=1\n",
    "                            elif 'Operator' in lines[i]:\n",
    "                                i+=3\n",
    "                            elif lines[i][:3] == '---':\n",
    "                                i+=1\n",
    "                            elif '[' in lines[i]:\n",
    "                                i+=2\n",
    "                            else:\n",
    "                                qna.append(lines[i].rstrip())\n",
    "                                i+=1\n",
    "                    else:\n",
    "                        i+=1\n",
    "                \n",
    "                if lines[0][0] == 'Q':\n",
    "                    quarter = lines[0].split(' ')[0]\n",
    "                    year = lines[0].split(' ')[1]\n",
    "                else:\n",
    "                    quarter = lines[1].split(' ')[0]\n",
    "                    year = lines[1].split(' ')[1]\n",
    "                cleansummary = []\n",
    "#                 print(j)\n",
    "                for i in range(len(summary)):\n",
    "                    if '--' in summary[i]:\n",
    "                        i+=1\n",
    "                    elif 'Operator' in summary[i]:\n",
    "                        i+=3\n",
    "                    elif '[' in summary[i]:\n",
    "#                         print(i, summary[i])\n",
    "                        i+=1\n",
    "                    else:\n",
    "                        cleansummary.append(summary[i])\n",
    "                summary_para = ' '.join(cleansummary).rstrip()\n",
    "                qna_para = ' '.join(qna).rstrip()\n",
    "                totalsummary += summary_para\n",
    "                totalqna = qna_para\n",
    "                allinfo.append(quarter)\n",
    "                allinfo.append(year)\n",
    "                allinfo.append(companies[company])\n",
    "                allinfo.append(summary_para)\n",
    "                allinfo.append(qna_para)\n",
    "                df.append(allinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3d81052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Q&amp;A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2019</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Hello, and welcome to our Q4 2019 f...</td>\n",
       "      <td>Great. Really appreciate this. Just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Good day, everyone, and welcome to t...</td>\n",
       "      <td>Thanks a lot. Lots here, but interna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2019</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Hello, and welcome to our Q3 2019 F...</td>\n",
       "      <td>I wanted to know if I can go a littl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2020</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>For opening remarks, I will be turning the cal...</td>\n",
       "      <td>Great. First, I just wanted to ask, within the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2019</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Hello, and welcome to our Q1 2019 f...</td>\n",
       "      <td>Okay. I'm going to ask 2 questions b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2018</td>\n",
       "      <td>Cisco</td>\n",
       "      <td>Welcome to Cisco's First Quarter of ...</td>\n",
       "      <td>Our first question comes from the li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2018</td>\n",
       "      <td>Cisco</td>\n",
       "      <td>Welcome to Cisco's Third Quarter Fis...</td>\n",
       "      <td>James Faucette from Morgan Stanley I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Cisco</td>\n",
       "      <td>Welcome to Cisco Systems' Third Quar...</td>\n",
       "      <td>I wanted to see if we could understa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2020</td>\n",
       "      <td>Cisco</td>\n",
       "      <td>Thanks, Michelle. Welcome, everyone, to Cisco...</td>\n",
       "      <td>Our first question comes from Paul Silverstein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2016</td>\n",
       "      <td>Cisco</td>\n",
       "      <td>Thanks, Sam. Welcome, everyone, to Cisco's fo...</td>\n",
       "      <td>Thank you. And our first question comes from t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Quarter  Year Company                                            Summary  \\\n",
       "0        Q4  2019  Amazon             Hello, and welcome to our Q4 2019 f...   \n",
       "1        Q1  2016  Amazon            Good day, everyone, and welcome to t...   \n",
       "2        Q3  2019  Amazon             Hello, and welcome to our Q3 2019 F...   \n",
       "3        Q1  2020  Amazon  For opening remarks, I will be turning the cal...   \n",
       "4        Q1  2019  Amazon             Hello, and welcome to our Q1 2019 f...   \n",
       "..      ...   ...     ...                                                ...   \n",
       "183      Q1  2018   Cisco            Welcome to Cisco's First Quarter of ...   \n",
       "184      Q3  2018   Cisco            Welcome to Cisco's Third Quarter Fis...   \n",
       "185      Q3  2017   Cisco            Welcome to Cisco Systems' Third Quar...   \n",
       "186      Q3  2020   Cisco   Thanks, Michelle. Welcome, everyone, to Cisco...   \n",
       "187      Q4  2016   Cisco   Thanks, Sam. Welcome, everyone, to Cisco's fo...   \n",
       "\n",
       "                                                   Q&A  \n",
       "0              Great. Really appreciate this. Just ...  \n",
       "1              Thanks a lot. Lots here, but interna...  \n",
       "2              I wanted to know if I can go a littl...  \n",
       "3    Great. First, I just wanted to ask, within the...  \n",
       "4              Okay. I'm going to ask 2 questions b...  \n",
       "..                                                 ...  \n",
       "183            Our first question comes from the li...  \n",
       "184            James Faucette from Morgan Stanley I...  \n",
       "185            I wanted to see if we could understa...  \n",
       "186  Our first question comes from Paul Silverstein...  \n",
       "187  Thank you. And our first question comes from t...  \n",
       "\n",
       "[188 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earnings_transcript_df = pd.DataFrame(df)\n",
    "earnings_transcript_df.columns =['Quarter','Year','Company','Summary','Q&A']\n",
    "\n",
    "earnings_transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0c92876",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = Counter(totalsummary.split(' '))\n",
    "words += Counter(totalqna.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a059e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgTxtLen(df):\n",
    "    avg_length_summary_after_preprocessing = str(df['Summary'].str.len().mean()) \n",
    "    avg_length_qna_after_preprocessing = str(df['Q&A'].str.len().mean()) \n",
    "    print(avg_length_summary_after_preprocessing)\n",
    "    print(avg_length_qna_after_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e57942cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove URLS\n",
      "16292.622340425532\n",
      "28507.35106382979\n",
      "remove HTML tags\n",
      "16292.617021276596\n",
      "28088.063829787236\n",
      "remove extra whitespaces\n",
      "16292.617021276596\n",
      "28088.063829787236\n",
      "remove contractions\n",
      "16065.97340425532\n",
      "27840.127659574468\n",
      "Remove characters following digits such as 1st, 2nd or 3rd\n",
      "16065.97340425532\n",
      "27840.127659574468\n",
      "Replace hyphens with space\n",
      "16065.97340425532\n",
      "27840.127659574468\n",
      "remove non alphabetical characters\n",
      "16065.97340425532\n",
      "27840.127659574468\n"
     ]
    }
   ],
   "source": [
    "def strip_html_tags(text): \n",
    "    soup = BeautifulSoup(text, \"html.parser\") \n",
    "    stripped_text = soup.get_text(separator=\" \") \n",
    "    return stripped_text \n",
    "    \n",
    "# Make lowercase\n",
    "earnings_transcript_df[\"Summary\"] = earnings_transcript_df[\"Summary\"].str.lower()\n",
    "earnings_transcript_df[\"Q&A\"] = earnings_transcript_df[\"Q&A\"].str.lower()\n",
    "\n",
    "# Remove URLS\n",
    "earnings_transcript_df['Summary']= earnings_transcript_df['Summary'].str.replace('http(s)?:\\/\\/.*', '', regex=True)\n",
    "earnings_transcript_df['Q&A']= earnings_transcript_df['Q&A'].str.replace('http(s)?:\\/\\/.*', '', regex=True)\n",
    "print(\"Remove URLS\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# remove HTML tags\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].apply(lambda x: strip_html_tags(x))\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].apply(lambda x: strip_html_tags(x))\n",
    "print(\"remove HTML tags\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# remove extra whitespaces\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].replace(r'/\\s/\\s+/g', ' ', regex=True)\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].replace(r'/\\s/\\s+/g', ' ', regex=True)\n",
    "print(\"remove extra whitespaces\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# remove contractions\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].apply(lambda x: ' '.join([contractions.fix(word) for word in x.split()]))\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].apply(lambda x: ' '.join([contractions.fix(word) for word in x.split()]))\n",
    "print(\"remove contractions\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# Remove characters following digits such as 1st, 2nd or 3rd\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].str.replace('\\b\\d+\\w+\\b', '', regex=True)\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].str.replace('\\b\\d+\\w+\\b', '', regex=True)\n",
    "print(\"Remove characters following digits such as 1st, 2nd or 3rd\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# Replace hyphens with space\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].replace('/\\b-\\b/g', ' ', regex=True)\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].replace('/\\b-\\b/g', ' ', regex=True)\n",
    "print(\"Replace hyphens with space\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n",
    "# remove non alphanumeric characters\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].str.replace('[^a-zA-Z0-9 ]', ' ')\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].str.replace('[^a-zA-Z0-9 ]', ' ')\n",
    "print(\"remove non alphabetical characters\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5811e74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords\n",
      "11871.898936170213\n",
      "16657.393617021276\n",
      "Lemmatize\n",
      "11406.505319148937\n",
      "15969.808510638299\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words) ]))\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].astype('string')\n",
    "\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words) ]))\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].astype('string')\n",
    "\n",
    "print(\"Stopwords\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "# Lemmatize the Dataset\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_review(text):\n",
    "    return ' '.join(lemmatizer.lemmatize(w,pos=\"v\") for w in w_tokenizer.tokenize(text))\n",
    "\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].apply(lemmatize_review)\n",
    "earnings_transcript_df['Summary'] = earnings_transcript_df['Summary'].astype('string')\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].apply(lemmatize_review)\n",
    "earnings_transcript_df['Q&A'] = earnings_transcript_df['Q&A'].astype('string')\n",
    "print(\"Lemmatize\")\n",
    "getAvgTxtLen(earnings_transcript_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8860f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11406.505319148937\n",
      "15969.808510638299\n"
     ]
    }
   ],
   "source": [
    "avg_length_summary_after_preprocessing = str(earnings_transcript_df['Summary'].str.len().mean()) \n",
    "avg_length_qna_after_preprocessing = str(earnings_transcript_df['Q&A'].str.len().mean()) \n",
    "print(avg_length_summary_after_preprocessing)\n",
    "print(avg_length_qna_after_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "099ffde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Q&amp;A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2019</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>hello welcome q4 2019 financial result confere...</td>\n",
       "      <td>great really appreciate aws business look sort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>good day everyone welcome amazon com q1 2016 f...</td>\n",
       "      <td>thank lot lot international retail revenue int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2019</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>hello welcome q3 2019 financial result confere...</td>\n",
       "      <td>want know go little bite deeper framework give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2020</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>open remark turn call director investor relati...</td>\n",
       "      <td>great first want ask within 4 billion covid re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2019</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>hello welcome q1 2019 financial result confere...</td>\n",
       "      <td>okay go ask 2 question first one really simple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2018</td>\n",
       "      <td>Cisco</td>\n",
       "      <td>welcome cisco first quarter fiscal year 2018 f...</td>\n",
       "      <td>first question come line pierre ferragu sanfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2018</td>\n",
       "      <td>Cisco</td>\n",
       "      <td>welcome cisco third quarter fiscal year 2018 f...</td>\n",
       "      <td>jam faucette morgan stanley investment researc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Cisco</td>\n",
       "      <td>welcome cisco systems third quarter fiscal yea...</td>\n",
       "      <td>want see could understand guidance kelly chuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2020</td>\n",
       "      <td>Cisco</td>\n",
       "      <td>thank michelle welcome everyone cisco third qu...</td>\n",
       "      <td>first question come paul silverstein cowen com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2016</td>\n",
       "      <td>Cisco</td>\n",
       "      <td>thank sam welcome everyone cisco fourth quarte...</td>\n",
       "      <td>thank first question come line vijay bhagavath...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Quarter  Year Company                                            Summary  \\\n",
       "0        Q4  2019  Amazon  hello welcome q4 2019 financial result confere...   \n",
       "1        Q1  2016  Amazon  good day everyone welcome amazon com q1 2016 f...   \n",
       "2        Q3  2019  Amazon  hello welcome q3 2019 financial result confere...   \n",
       "3        Q1  2020  Amazon  open remark turn call director investor relati...   \n",
       "4        Q1  2019  Amazon  hello welcome q1 2019 financial result confere...   \n",
       "..      ...   ...     ...                                                ...   \n",
       "183      Q1  2018   Cisco  welcome cisco first quarter fiscal year 2018 f...   \n",
       "184      Q3  2018   Cisco  welcome cisco third quarter fiscal year 2018 f...   \n",
       "185      Q3  2017   Cisco  welcome cisco systems third quarter fiscal yea...   \n",
       "186      Q3  2020   Cisco  thank michelle welcome everyone cisco third qu...   \n",
       "187      Q4  2016   Cisco  thank sam welcome everyone cisco fourth quarte...   \n",
       "\n",
       "                                                   Q&A  \n",
       "0    great really appreciate aws business look sort...  \n",
       "1    thank lot lot international retail revenue int...  \n",
       "2    want know go little bite deeper framework give...  \n",
       "3    great first want ask within 4 billion covid re...  \n",
       "4    okay go ask 2 question first one really simple...  \n",
       "..                                                 ...  \n",
       "183  first question come line pierre ferragu sanfor...  \n",
       "184  jam faucette morgan stanley investment researc...  \n",
       "185  want see could understand guidance kelly chuck...  \n",
       "186  first question come paul silverstein cowen com...  \n",
       "187  thank first question come line vijay bhagavath...  \n",
       "\n",
       "[188 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.iloc[0,3]\n",
    "earnings_transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6a27d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running augmentations\n",
    "augdf = earnings_transcript_df.copy()\n",
    "aug = naw.SynonymAug(aug_src='wordnet', model_path=None, name='Synonym_Aug', aug_min=10, aug_max=60, aug_p=0.3)\n",
    "for i in range(len(augdf)):\n",
    "    k = aug.augment(earnings_transcript_df.iloc[i]['Summary'],n=1)\n",
    "    augdf['Summary'][i] = k[0]\n",
    "    k = aug.augment(earnings_transcript_df.iloc[i]['Q&A'],n=1)\n",
    "    augdf['Q&A'][i] = k[0]\n",
    "\n",
    "earnings_transcript_df = earnings_transcript_df.append(augdf)\n",
    "earnings_transcript_df = earnings_transcript_df.reset_index().drop(columns = ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e5540d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>date</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>percent change (between t-2 and t+2)</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>Q4</td>\n",
       "      <td>2022</td>\n",
       "      <td>-3.79257</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>2022-08-24</td>\n",
       "      <td>Q3</td>\n",
       "      <td>2022</td>\n",
       "      <td>5.160274</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>Q2</td>\n",
       "      <td>2022</td>\n",
       "      <td>5.639725</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>Q1</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.989006</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>2021-11-17</td>\n",
       "      <td>Q4</td>\n",
       "      <td>2021</td>\n",
       "      <td>5.495411</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>Q1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3.557926</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2016-10-20</td>\n",
       "      <td>Q4</td>\n",
       "      <td>2016</td>\n",
       "      <td>3.468597</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2016-07-19</td>\n",
       "      <td>Q3</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.115477</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2016-04-21</td>\n",
       "      <td>Q2</td>\n",
       "      <td>2016</td>\n",
       "      <td>-8.175201</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>Q1</td>\n",
       "      <td>2016</td>\n",
       "      <td>5.597102</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Company        date Quarter  Year percent change (between t-2 and t+2)  \\\n",
       "0       NVIDIA  2022-11-16      Q4  2022                             -3.79257   \n",
       "1       NVIDIA  2022-08-24      Q3  2022                             5.160274   \n",
       "2       NVIDIA  2022-05-25      Q2  2022                             5.639725   \n",
       "3       NVIDIA  2022-02-16      Q1  2022                             0.989006   \n",
       "4       NVIDIA  2021-11-17      Q4  2021                             5.495411   \n",
       "..         ...         ...     ...   ...                                  ...   \n",
       "275  Microsoft  2017-01-26      Q1  2017                             3.557926   \n",
       "276  Microsoft  2016-10-20      Q4  2016                             3.468597   \n",
       "277  Microsoft  2016-07-19      Q3  2016                             4.115477   \n",
       "278  Microsoft  2016-04-21      Q2  2016                            -8.175201   \n",
       "279  Microsoft  2016-01-28      Q1  2016                             5.597102   \n",
       "\n",
       "    Sentiment  \n",
       "0    Negative  \n",
       "1    Positive  \n",
       "2    Positive  \n",
       "3     Neutral  \n",
       "4    Positive  \n",
       "..        ...  \n",
       "275  Positive  \n",
       "276  Positive  \n",
       "277  Positive  \n",
       "278  Negative  \n",
       "279  Positive  \n",
       "\n",
       "[280 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = pd.to_datetime(\"today\")\n",
    "\n",
    "# Consolidated Dataframe with sentiments for all companies\n",
    "finance_df = pd.DataFrame(columns=[\"Company\", \"date\", \"Quarter\", \"Year\", \"percent change (between t-2 and t+2)\",\"Sentiment\"])\n",
    "\n",
    "company_tickers = ['NVDA','MU','INTC','GOOGL','CSCO','ASML','AMZN','AMD','AAPL','MSFT']\n",
    "\n",
    "price_change_perc_threshold_for_sentiment = 3.0\n",
    "\n",
    "for ticker in company_tickers:\n",
    "    \n",
    "    # Get List of dates for Earnings call\n",
    "    ticker_data = yf.Ticker(ticker)\n",
    "    ticker_data.earnings_dates.reset_index(inplace=True)\n",
    "    \n",
    "    #Format Date column\n",
    "    ticker_data.earnings_dates[\"Earnings Date\"] = ticker_data.earnings_dates[\"Earnings Date\"].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    # Filter dates within window of our Transcripts\n",
    "    earnings_dates_df = ticker_data.earnings_dates[(ticker_data.earnings_dates[\"Earnings Date\"]<=today.strftime('%Y-%m-%d')) & (ticker_data.earnings_dates[\"Earnings Date\"]>=\"2015-12-01\")]\n",
    "    earning_call_dates= earnings_dates_df.iloc[:,0]\n",
    "\n",
    "    #print(earning_call_dates)\n",
    "    \n",
    "    prepared_df = pd.DataFrame(columns=[\"Company\", \"date\", \"Quarter\", \"Year\", \"percent change (between t-2 and t+2)\",\"Sentiment\"])\n",
    "    \n",
    "    historical_data = yf.download(ticker, start=\"2015-12-01\", end=\"2022-11-21\", interval=\"1d\")\n",
    "\n",
    "    historical_data.reset_index(inplace=True)\n",
    "\n",
    "    for date in earning_call_dates:\n",
    "        # Compute Quarters for each date to join finance df with Transcripts DF created in above cells\n",
    "        month=pd.to_datetime(date).month\n",
    "        year=pd.to_datetime(date).year\n",
    "        if month<=3:\n",
    "            quarter=\"Q1\"\n",
    "        elif month<=6:\n",
    "            quarter=\"Q2\"\n",
    "        elif month<=9:\n",
    "            quarter=\"Q3\"\n",
    "        else:\n",
    "            quarter=\"Q4\"\n",
    "                \n",
    "        # Compute % change by looking at T-2 and T+2 window from earnings call date\n",
    "        # i.e. if Earnings call is 27 Oct 2022 => compute:\n",
    "        # => (Closing_price['29 Oct'] - Closing_price['27 Oct']) * 100 / (Closing_price['27 Oct'])\n",
    "        \n",
    "        index= historical_data.index[historical_data[\"Date\"]==pd.to_datetime(date)]\n",
    "        tplus2= float(historical_data.loc[index+1,\"Adj Close\"])\n",
    "        tminus2 = float(historical_data.loc[index-2,\"Adj Close\"])\n",
    "        change = (tplus2 - tminus2)*100/tminus2\n",
    "        \n",
    "        # Computer sentiment based on price change percentage threshold\n",
    "        if abs(change)< price_change_perc_threshold_for_sentiment:\n",
    "            label=\"Neutral\"\n",
    "        elif change> price_change_perc_threshold_for_sentiment:\n",
    "            label=\"Positive\"\n",
    "        else:\n",
    "            label=\"Negative\"\n",
    "        prepared_df = prepared_df.append({\"Company\":companies[ticker],\"date\":date,\"Quarter\":quarter, \"Year\": year, \"percent change (between t-2 and t+2)\": change, \"Sentiment\": label}, ignore_index=True)\n",
    "    prepared_df.reset_index(drop=True)\n",
    "    prepared_df.to_csv(\"..\\\\data\\\\OHLC\\\\\"+ticker+\".csv\", encoding='utf-8')\n",
    "    finance_df=pd.concat([finance_df, prepared_df], ignore_index=True)\n",
    "finance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28a0952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_df.Year = finance_df.Year.astype('int')\n",
    "earnings_transcript_df.Year = earnings_transcript_df.Year.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38ed5933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Q&amp;A</th>\n",
       "      <th>date</th>\n",
       "      <th>percent change (between t-2 and t+2)</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2018</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2q18 review c 1 result 1 new march qtr record ...</td>\n",
       "      <td>want ask thoughts sort iphone position couple ...</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>8.778961</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2018</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2q18 inspection c one result 1 new march qtr r...</td>\n",
       "      <td>want ask thoughts sort iphone position couple ...</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>8.778961</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2019</td>\n",
       "      <td>Apple</td>\n",
       "      <td>4q19 review c 1 overview 1 co highest revenue ...</td>\n",
       "      <td>congratulations quarter iphone revenue traject...</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>-0.116452</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2019</td>\n",
       "      <td>Apple</td>\n",
       "      <td>4q19 review c 1 overview 1 co highest revenue ...</td>\n",
       "      <td>congratulations quarter iphone revenue traject...</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>-0.116452</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1q16 business review c 1 highlight 1 time reco...</td>\n",
       "      <td>hello thank much term march quarter guidance i...</td>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>-7.887974</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1q16 business review c 1 highlight 1 sentence ...</td>\n",
       "      <td>hello thank much term march quarter guidance i...</td>\n",
       "      <td>2016-01-26</td>\n",
       "      <td>-7.887974</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2020</td>\n",
       "      <td>Apple</td>\n",
       "      <td>3q20 review c 1 highlight 1 uncertain environm...</td>\n",
       "      <td>tim light economic adversity talk prepare rema...</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>13.948677</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2020</td>\n",
       "      <td>Apple</td>\n",
       "      <td>3q20 review c 1 highlight 1 uncertain environm...</td>\n",
       "      <td>tim light economic adversity talk prepare rema...</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>13.948677</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Apple</td>\n",
       "      <td>3q17 review c 1 highlight 1 unit revenue grow ...</td>\n",
       "      <td>luca first question gross margin guidance stro...</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>5.11036</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Apple</td>\n",
       "      <td>3q17 review c 1 highlight 1 unit revenue grow ...</td>\n",
       "      <td>luca first question gross margin guidance stro...</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>5.11036</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2020</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1q20 review c 1 highlight 1 thrill report co b...</td>\n",
       "      <td>guess first one wearables fairly impressive se...</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>1.894345</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2020</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1q20 review c 1 highlight 1 thrill report co b...</td>\n",
       "      <td>guess first one wearables fairly impressive se...</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>1.894345</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>good day everyone welcome apple incorporate se...</td>\n",
       "      <td>first question actually clarification term put...</td>\n",
       "      <td>2016-04-26</td>\n",
       "      <td>-7.43755</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>good day everyone welcome apple incorporate se...</td>\n",
       "      <td>first question actually clarification term put...</td>\n",
       "      <td>2016-04-26</td>\n",
       "      <td>-7.43755</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2017</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1q17 review c 1 overview 1 generate highest qu...</td>\n",
       "      <td>yes thank first luca factor cause widen gross ...</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>5.576058</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2017</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1q17 review c unity overview 1 generate highes...</td>\n",
       "      <td>yes thank first luca factor cause widen gross ...</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>5.576058</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2019</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2q19 review c 1 highlight 1 revenue 58b toward...</td>\n",
       "      <td>tim talk bite see china clearly look like thin...</td>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>3.044552</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2019</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2q19 review c 1 highlight 1 revenue 58b toward...</td>\n",
       "      <td>tim talk bite see china clearly look like thin...</td>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>3.044552</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2017</td>\n",
       "      <td>Apple</td>\n",
       "      <td>4q17 review c 1 highlight 1 biggest year ever ...</td>\n",
       "      <td>luca expect catch iphone x demand give likely ...</td>\n",
       "      <td>2017-11-02</td>\n",
       "      <td>2.046839</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2017</td>\n",
       "      <td>Apple</td>\n",
       "      <td>4q17 reappraisal c 1 highlight 1 biggest year ...</td>\n",
       "      <td>luca expect catch iphone x demand give likely ...</td>\n",
       "      <td>2017-11-02</td>\n",
       "      <td>2.046839</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>4q16 business review c 1 highlight 1 result se...</td>\n",
       "      <td>good afternoon congratulations tim month iphon...</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>-0.866205</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>4q16 business review c 1 highlight 1 result se...</td>\n",
       "      <td>good afternoon congratulations tim month iphon...</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>-0.866205</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>annotation n p 1 detail 1 instal base relate p...</td>\n",
       "      <td>thank much question tim talk little bite thoug...</td>\n",
       "      <td>2016-07-26</td>\n",
       "      <td>4.348269</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2016</td>\n",
       "      <td>Apple</td>\n",
       "      <td>annotation n p 1 detail 1 instal base relate p...</td>\n",
       "      <td>thank much question tim talk little bite thoug...</td>\n",
       "      <td>2016-07-26</td>\n",
       "      <td>4.348269</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2017</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2q17 business review c 1 highlight 1 report st...</td>\n",
       "      <td>first question luca around gross margin able e...</td>\n",
       "      <td>2017-05-02</td>\n",
       "      <td>2.37382</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2017</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2q17 business review c 1 highlight 1 report st...</td>\n",
       "      <td>maiden question luca around gross margin able ...</td>\n",
       "      <td>2017-05-02</td>\n",
       "      <td>2.37382</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2019</td>\n",
       "      <td>Apple</td>\n",
       "      <td>3q19 review c 1 overview 1 return growth new j...</td>\n",
       "      <td>guess 2 first could talk think september quart...</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>2.551256</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2019</td>\n",
       "      <td>Apple</td>\n",
       "      <td>3q19 review c 1 overview 1 return growth new j...</td>\n",
       "      <td>guess ii first could talk think september quar...</td>\n",
       "      <td>2019-07-30</td>\n",
       "      <td>2.551256</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2019</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1q19 business review c 1 highlight 1 december ...</td>\n",
       "      <td>service growth decelerate growth rat recent qu...</td>\n",
       "      <td>2019-01-29</td>\n",
       "      <td>4.747742</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2019</td>\n",
       "      <td>Apple</td>\n",
       "      <td>1q19 business review c 1 highlight 1 december ...</td>\n",
       "      <td>service growth decelerate growth rat recent qu...</td>\n",
       "      <td>2019-01-29</td>\n",
       "      <td>4.747742</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2018</td>\n",
       "      <td>Apple</td>\n",
       "      <td>3q18 review c 1 highlight 1 best june qtr reve...</td>\n",
       "      <td>ask question upfront first tim track hit servi...</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>5.508419</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2018</td>\n",
       "      <td>Apple</td>\n",
       "      <td>3q18 review c 1 highlight 1 best june qtr reve...</td>\n",
       "      <td>ask question upfront first tim track hit servi...</td>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>5.508419</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2018</td>\n",
       "      <td>Apple</td>\n",
       "      <td>annotation n p 1 note 1 1q18 include 13 weeks ...</td>\n",
       "      <td>luca want talk little bite comment capital str...</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>-3.874952</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2018</td>\n",
       "      <td>Apple</td>\n",
       "      <td>annotation n p 1 note 1 1q18 include 13 weeks ...</td>\n",
       "      <td>luca want talk little bite comment capital str...</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>-3.874952</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2018</td>\n",
       "      <td>Apple</td>\n",
       "      <td>good day welcome apple inc fourth quarter fisc...</td>\n",
       "      <td>first question come wamsi mohan bank america m...</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>-2.728567</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2018</td>\n",
       "      <td>Apple</td>\n",
       "      <td>good day welcome apple inc fourth quarter fisc...</td>\n",
       "      <td>beginning question come wamsi mohan bank ameri...</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>-2.728567</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2020</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2q20 review c 1 overview 1 revenue 58 3b 1 tim...</td>\n",
       "      <td>hope everyone well tim talk see improvement se...</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>3.765525</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Q2</td>\n",
       "      <td>2020</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2q20 reappraisal c 1 overview 1 revenue 58 3b ...</td>\n",
       "      <td>hope everyone well tim talk see improvement se...</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>3.765525</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quarter  Year Company                                            Summary  \\\n",
       "36      Q2  2018   Apple  2q18 review c 1 result 1 new march qtr record ...   \n",
       "37      Q2  2018   Apple  2q18 inspection c one result 1 new march qtr r...   \n",
       "38      Q4  2019   Apple  4q19 review c 1 overview 1 co highest revenue ...   \n",
       "39      Q4  2019   Apple  4q19 review c 1 overview 1 co highest revenue ...   \n",
       "40      Q1  2016   Apple  1q16 business review c 1 highlight 1 time reco...   \n",
       "41      Q1  2016   Apple  1q16 business review c 1 highlight 1 sentence ...   \n",
       "42      Q3  2020   Apple  3q20 review c 1 highlight 1 uncertain environm...   \n",
       "43      Q3  2020   Apple  3q20 review c 1 highlight 1 uncertain environm...   \n",
       "44      Q3  2017   Apple  3q17 review c 1 highlight 1 unit revenue grow ...   \n",
       "45      Q3  2017   Apple  3q17 review c 1 highlight 1 unit revenue grow ...   \n",
       "46      Q1  2020   Apple  1q20 review c 1 highlight 1 thrill report co b...   \n",
       "47      Q1  2020   Apple  1q20 review c 1 highlight 1 thrill report co b...   \n",
       "48      Q2  2016   Apple  good day everyone welcome apple incorporate se...   \n",
       "49      Q2  2016   Apple  good day everyone welcome apple incorporate se...   \n",
       "50      Q1  2017   Apple  1q17 review c 1 overview 1 generate highest qu...   \n",
       "51      Q1  2017   Apple  1q17 review c unity overview 1 generate highes...   \n",
       "52      Q2  2019   Apple  2q19 review c 1 highlight 1 revenue 58b toward...   \n",
       "53      Q2  2019   Apple  2q19 review c 1 highlight 1 revenue 58b toward...   \n",
       "54      Q4  2017   Apple  4q17 review c 1 highlight 1 biggest year ever ...   \n",
       "55      Q4  2017   Apple  4q17 reappraisal c 1 highlight 1 biggest year ...   \n",
       "56      Q4  2016   Apple  4q16 business review c 1 highlight 1 result se...   \n",
       "57      Q4  2016   Apple  4q16 business review c 1 highlight 1 result se...   \n",
       "58      Q3  2016   Apple  annotation n p 1 detail 1 instal base relate p...   \n",
       "59      Q3  2016   Apple  annotation n p 1 detail 1 instal base relate p...   \n",
       "60      Q2  2017   Apple  2q17 business review c 1 highlight 1 report st...   \n",
       "61      Q2  2017   Apple  2q17 business review c 1 highlight 1 report st...   \n",
       "62      Q3  2019   Apple  3q19 review c 1 overview 1 return growth new j...   \n",
       "63      Q3  2019   Apple  3q19 review c 1 overview 1 return growth new j...   \n",
       "64      Q1  2019   Apple  1q19 business review c 1 highlight 1 december ...   \n",
       "65      Q1  2019   Apple  1q19 business review c 1 highlight 1 december ...   \n",
       "66      Q3  2018   Apple  3q18 review c 1 highlight 1 best june qtr reve...   \n",
       "67      Q3  2018   Apple  3q18 review c 1 highlight 1 best june qtr reve...   \n",
       "68      Q1  2018   Apple  annotation n p 1 note 1 1q18 include 13 weeks ...   \n",
       "69      Q1  2018   Apple  annotation n p 1 note 1 1q18 include 13 weeks ...   \n",
       "70      Q4  2018   Apple  good day welcome apple inc fourth quarter fisc...   \n",
       "71      Q4  2018   Apple  good day welcome apple inc fourth quarter fisc...   \n",
       "72      Q2  2020   Apple  2q20 review c 1 overview 1 revenue 58 3b 1 tim...   \n",
       "73      Q2  2020   Apple  2q20 reappraisal c 1 overview 1 revenue 58 3b ...   \n",
       "\n",
       "                                                  Q&A        date  \\\n",
       "36  want ask thoughts sort iphone position couple ...  2018-05-01   \n",
       "37  want ask thoughts sort iphone position couple ...  2018-05-01   \n",
       "38  congratulations quarter iphone revenue traject...  2019-10-30   \n",
       "39  congratulations quarter iphone revenue traject...  2019-10-30   \n",
       "40  hello thank much term march quarter guidance i...  2016-01-26   \n",
       "41  hello thank much term march quarter guidance i...  2016-01-26   \n",
       "42  tim light economic adversity talk prepare rema...  2020-07-30   \n",
       "43  tim light economic adversity talk prepare rema...  2020-07-30   \n",
       "44  luca first question gross margin guidance stro...  2017-08-01   \n",
       "45  luca first question gross margin guidance stro...  2017-08-01   \n",
       "46  guess first one wearables fairly impressive se...  2020-01-28   \n",
       "47  guess first one wearables fairly impressive se...  2020-01-28   \n",
       "48  first question actually clarification term put...  2016-04-26   \n",
       "49  first question actually clarification term put...  2016-04-26   \n",
       "50  yes thank first luca factor cause widen gross ...  2017-01-31   \n",
       "51  yes thank first luca factor cause widen gross ...  2017-01-31   \n",
       "52  tim talk bite see china clearly look like thin...  2019-04-30   \n",
       "53  tim talk bite see china clearly look like thin...  2019-04-30   \n",
       "54  luca expect catch iphone x demand give likely ...  2017-11-02   \n",
       "55  luca expect catch iphone x demand give likely ...  2017-11-02   \n",
       "56  good afternoon congratulations tim month iphon...  2016-10-25   \n",
       "57  good afternoon congratulations tim month iphon...  2016-10-25   \n",
       "58  thank much question tim talk little bite thoug...  2016-07-26   \n",
       "59  thank much question tim talk little bite thoug...  2016-07-26   \n",
       "60  first question luca around gross margin able e...  2017-05-02   \n",
       "61  maiden question luca around gross margin able ...  2017-05-02   \n",
       "62  guess 2 first could talk think september quart...  2019-07-30   \n",
       "63  guess ii first could talk think september quar...  2019-07-30   \n",
       "64  service growth decelerate growth rat recent qu...  2019-01-29   \n",
       "65  service growth decelerate growth rat recent qu...  2019-01-29   \n",
       "66  ask question upfront first tim track hit servi...  2018-07-31   \n",
       "67  ask question upfront first tim track hit servi...  2018-07-31   \n",
       "68  luca want talk little bite comment capital str...  2018-02-01   \n",
       "69  luca want talk little bite comment capital str...  2018-02-01   \n",
       "70  first question come wamsi mohan bank america m...  2018-11-01   \n",
       "71  beginning question come wamsi mohan bank ameri...  2018-11-01   \n",
       "72  hope everyone well tim talk see improvement se...  2020-04-30   \n",
       "73  hope everyone well tim talk see improvement se...  2020-04-30   \n",
       "\n",
       "   percent change (between t-2 and t+2) Sentiment  \n",
       "36                             8.778961  Positive  \n",
       "37                             8.778961  Positive  \n",
       "38                            -0.116452   Neutral  \n",
       "39                            -0.116452   Neutral  \n",
       "40                            -7.887974  Negative  \n",
       "41                            -7.887974  Negative  \n",
       "42                            13.948677  Positive  \n",
       "43                            13.948677  Positive  \n",
       "44                              5.11036  Positive  \n",
       "45                              5.11036  Positive  \n",
       "46                             1.894345   Neutral  \n",
       "47                             1.894345   Neutral  \n",
       "48                             -7.43755  Negative  \n",
       "49                             -7.43755  Negative  \n",
       "50                             5.576058  Positive  \n",
       "51                             5.576058  Positive  \n",
       "52                             3.044552  Positive  \n",
       "53                             3.044552  Positive  \n",
       "54                             2.046839   Neutral  \n",
       "55                             2.046839   Neutral  \n",
       "56                            -0.866205   Neutral  \n",
       "57                            -0.866205   Neutral  \n",
       "58                             4.348269  Positive  \n",
       "59                             4.348269  Positive  \n",
       "60                              2.37382   Neutral  \n",
       "61                              2.37382   Neutral  \n",
       "62                             2.551256   Neutral  \n",
       "63                             2.551256   Neutral  \n",
       "64                             4.747742  Positive  \n",
       "65                             4.747742  Positive  \n",
       "66                             5.508419  Positive  \n",
       "67                             5.508419  Positive  \n",
       "68                            -3.874952  Negative  \n",
       "69                            -3.874952  Negative  \n",
       "70                            -2.728567   Neutral  \n",
       "71                            -2.728567   Neutral  \n",
       "72                             3.765525  Positive  \n",
       "73                             3.765525  Positive  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged = pd.merge(earnings_transcript_df, finance_df, on=['Company', 'Year', 'Quarter'], how='inner')\n",
    "df_merged[df_merged['Company']=='Apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7a42804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Q&amp;A</th>\n",
       "      <th>date</th>\n",
       "      <th>percent change (between t-2 and t+2)</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2019</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>hello welcome q4 2019 financial result confere...</td>\n",
       "      <td>great really appreciate aws business look sort...</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>-0.24919</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2019</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>hello welcome q4 2019 financial result confere...</td>\n",
       "      <td>great really appreciate aws business look sort...</td>\n",
       "      <td>2019-10-24</td>\n",
       "      <td>-0.24919</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>good day everyone welcome amazon com q1 2016 f...</td>\n",
       "      <td>thank lot lot international retail revenue int...</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>-2.370061</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>near day everyone welcome amazon com q1 2016 f...</td>\n",
       "      <td>thank lot lot international retail revenue int...</td>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>-2.370061</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2019</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>hello welcome q3 2019 financial result confere...</td>\n",
       "      <td>want know go little bite deeper framework give...</td>\n",
       "      <td>2019-07-25</td>\n",
       "      <td>-2.579112</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quarter  Year Company                                            Summary  \\\n",
       "0      Q4  2019  Amazon  hello welcome q4 2019 financial result confere...   \n",
       "1      Q4  2019  Amazon  hello welcome q4 2019 financial result confere...   \n",
       "2      Q1  2016  Amazon  good day everyone welcome amazon com q1 2016 f...   \n",
       "3      Q1  2016  Amazon  near day everyone welcome amazon com q1 2016 f...   \n",
       "4      Q3  2019  Amazon  hello welcome q3 2019 financial result confere...   \n",
       "\n",
       "                                                 Q&A        date  \\\n",
       "0  great really appreciate aws business look sort...  2019-10-24   \n",
       "1  great really appreciate aws business look sort...  2019-10-24   \n",
       "2  thank lot lot international retail revenue int...  2016-01-28   \n",
       "3  thank lot lot international retail revenue int...  2016-01-28   \n",
       "4  want know go little bite deeper framework give...  2019-07-25   \n",
       "\n",
       "  percent change (between t-2 and t+2) Sentiment  \n",
       "0                             -0.24919   Neutral  \n",
       "1                             -0.24919   Neutral  \n",
       "2                            -2.370061   Neutral  \n",
       "3                            -2.370061   Neutral  \n",
       "4                            -2.579112   Neutral  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6ea32dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(\"../data/OHLC/all_tickers.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34698df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Company</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Q&amp;A</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2019</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>hello welcome q4 2019 financial result confere...</td>\n",
       "      <td>great really appreciate aws business look sort...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q4</td>\n",
       "      <td>2019</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>hello welcome q4 2019 financial result confere...</td>\n",
       "      <td>great really appreciate aws business look sort...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>good day everyone welcome amazon com q1 2016 f...</td>\n",
       "      <td>thank lot lot international retail revenue int...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2016</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>near day everyone welcome amazon com q1 2016 f...</td>\n",
       "      <td>thank lot lot international retail revenue int...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q3</td>\n",
       "      <td>2019</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>hello welcome q3 2019 financial result confere...</td>\n",
       "      <td>want know go little bite deeper framework give...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quarter  Year Company                                            Summary  \\\n",
       "0      Q4  2019  Amazon  hello welcome q4 2019 financial result confere...   \n",
       "1      Q4  2019  Amazon  hello welcome q4 2019 financial result confere...   \n",
       "2      Q1  2016  Amazon  good day everyone welcome amazon com q1 2016 f...   \n",
       "3      Q1  2016  Amazon  near day everyone welcome amazon com q1 2016 f...   \n",
       "4      Q3  2019  Amazon  hello welcome q3 2019 financial result confere...   \n",
       "\n",
       "                                                 Q&A Sentiment  \n",
       "0  great really appreciate aws business look sort...   Neutral  \n",
       "1  great really appreciate aws business look sort...   Neutral  \n",
       "2  thank lot lot international retail revenue int...   Neutral  \n",
       "3  thank lot lot international retail revenue int...   Neutral  \n",
       "4  want know go little bite deeper framework give...   Neutral  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_merged\n",
    "df = df[['Quarter','Year','Company','Summary','Q&A','Sentiment']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "084cd296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec183700",
   "metadata": {},
   "source": [
    "# For summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408f9a3b",
   "metadata": {},
   "source": [
    "## Sentiment Analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0403c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['no_contract'] = df['Summary'].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
    "# df['no_contract'] = [' '.join(map(str, l)) for l in df['no_contract']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d11bf7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords_list = stopwords.words('english')\n",
    "# def ReviewProcessing(df):\n",
    "#   #remove extra spaces\n",
    "#     df['review_cleaned'] = df.no_contract.str.strip()\n",
    "    \n",
    "#   #remove html and url\n",
    "#     df.review_cleaned = df.review_cleaned.str.replace(r'<[^<>]* />', '', regex=True)\n",
    "#     df.review_cleaned = df.review_cleaned.apply(lambda x: re.sub(r\"http\\S+\", \"\", x))\n",
    "  \n",
    "#   # lowercase\n",
    "#     df.review_cleaned = df.review_cleaned.str.lower()\n",
    "    \n",
    "#   # remove non alphabetic \n",
    "#     df.review_cleaned = df.review_cleaned.apply(lambda x: re.sub(\"[^a-zA-Z]+\", \" \", x))\n",
    "    \n",
    "#   # split into list\n",
    "#     df.review_cleaned = df.review_cleaned.str.split(' ')\n",
    "    \n",
    "#   # remove stop words \n",
    "#     df['review_stopwords'] = df.review_cleaned.apply(lambda x: [item for item in x if item not in stopwords_list])\n",
    "#     return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f9cdf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_wordnet_pos(word):\n",
    "#     tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "#     tag_dict = {\"J\": wordnet.ADJ,\n",
    "#                 \"N\": wordnet.NOUN,\n",
    "#                 \"V\": wordnet.VERB,\n",
    "#                 \"R\": wordnet.ADV}\n",
    "\n",
    "#     return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "# lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "# def get_lemmatize(sent):\n",
    "#     return \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sent)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54d54e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# clean_data = ReviewProcessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2864ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_data.review_cleaned = clean_data.review_cleaned.apply(' '.join)\n",
    "# clean_data.review_stopwords = clean_data.review_stopwords.apply(' '.join)\n",
    "# clean_data['review_cleaned_lemmatized'] = clean_data.review_stopwords.apply(get_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9c8b982c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/jaimansukhani/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "65a23f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_dict = {'manipulate':-1,'manipulative':-1,'jamescharlesiscancelled':-1,'jamescharlesisoverparty':-1,\n",
    "#             'pedophile':-1,'pedo':-1,'cancel':-1,'cancelled':-1,'cancel culture':0.4,'teamtati':-1,'teamjames':1,\n",
    "#             'teamjamescharles':1,'liar':-1}\n",
    "word_dict = {'increase':1, 'increased':1, 'increases':1, \"increasing\":1, \"increasingly\":1, \"expand\":1,\n",
    "'expanded':1, \"expanding\":1, \"expands\":1, \"expansion\":1, \"expansions\":1, \"grow\":1,\n",
    "\"grows\":1, \"grew\":1, \"growth\":1, \"growths\":1, \"improve\":1, \"improved\":1, \"improves\":1,\n",
    "\"improvement\":1, \"improvements\":1, \"strong\":1, \"stronger\":1, \"strongest\":1, \"strongly\":1, \"decline\":-40, \n",
    "\"declined\":-40, \"declines\":-40, \"declining\":-40, \"deteriorate\":-40, \"deteriorates\":-40,\n",
    "\"deteriorated\":-40, \"deteriorating\":-40, \"compress\":-40, \"compressed\":-40, \"compresses\":-40,\n",
    "\"compressing\":-40, \"compressible\":-40, \"compression\":-40, \"reduce\":-40, \"reduces\":-40,\n",
    "\"reduced\":-40, \"reducing\":-40, \"reduction\":-40, \"reductions\":-40, \"weak\":-40, \"weaker\":-40,\n",
    "\"weakest\":-40, \"weaken\":-40, \"weakens\":-40, \"weakened\":-40, \"weakening\":-40, \"weakness\":-40,\n",
    "\"weaknesses\":-40}\n",
    "\n",
    "\n",
    "sid.lexicon.update(word_dict)\n",
    "\n",
    "list1 = []\n",
    "for i in df['Summary']:\n",
    "    list1.append((sid.polarity_scores(str(i)))['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0f3d6b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = pd.Series(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8d57b0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_category(sentiment):\n",
    "    label = ''\n",
    "    if(sentiment>0.9):\n",
    "        label = 'Positive'\n",
    "    elif(sentiment>0.6):\n",
    "        label = 'Neutral'\n",
    "    else:\n",
    "        label = 'Negative'\n",
    "    return(label)\n",
    "\n",
    "df['sentiment_category_analyser'] = df['score'].apply(sentiment_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e72f75a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    203\n",
       "Negative    157\n",
       "Neutral       6\n",
       "Name: sentiment_category_analyser, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment_category_analyser.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4cec31ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.3251366120218579\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in range(len(df['Sentiment'])):\n",
    "    if df['Sentiment'][i] == df['sentiment_category_analyser'][i]:\n",
    "        c += 1\n",
    "print(\"Accuracy: \", c/len(df['Sentiment']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e351211c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.32487911337021813\n",
      "Recall:  0.3586711711711712\n",
      "F1 score:  0.27513060427673247\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Precision: \", precision_score(df['Sentiment'], df[\"sentiment_category_analyser\"], average=\"macro\"))\n",
    "print(\"Recall: \", recall_score(df['Sentiment'], df[\"sentiment_category_analyser\"], average=\"macro\"))\n",
    "print(\"F1 score: \", f1_score(df['Sentiment'], df[\"sentiment_category_analyser\"], average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8da8de",
   "metadata": {},
   "source": [
    "## Text blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3cbf4df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /opt/miniconda3/lib/python3.9/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/miniconda3/lib/python3.9/site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: joblib in /opt/miniconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.63.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/miniconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2022.8.17)\n",
      "Requirement already satisfied: click in /opt/miniconda3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.1.3)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/opt/miniconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "773e63a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# compute sentiment scores (polarity) and labels\n",
    "sentiment_scores_tb = [round(TextBlob(article).sentiment.polarity, 2) for article in df['Summary']]\n",
    "sentiment_category_tb = ['Positive' if score > 0 \n",
    "                             else 'Negative' if score < 0 \n",
    "                                 else 'Neutral' \n",
    "                                     for score in sentiment_scores_tb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ae6fff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_category_tb'] = pd.DataFrame(sentiment_category_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2ccf70b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    362\n",
       "Negative      3\n",
       "Neutral       1\n",
       "Name: sentiment_category_tb, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment_category_tb.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1a73e8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.3524590163934426\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in range(len(df['Sentiment'])):\n",
    "    if df['Sentiment'][i] == df['sentiment_category_tb'][i]:\n",
    "        c += 1\n",
    "print(\"Accuracy: \", c/len(df['Sentiment']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "435ffc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.45119705340699817\n",
      "Recall:  0.3355855855855856\n",
      "F1 score:  0.17862393279459432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Precision: \", precision_score(df['Sentiment'], df[\"sentiment_category_tb\"], average=\"macro\"))\n",
    "print(\"Recall: \", recall_score(df['Sentiment'], df[\"sentiment_category_tb\"], average=\"macro\"))\n",
    "print(\"F1 score: \", f1_score(df['Sentiment'], df[\"sentiment_category_tb\"], average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eacc5c2",
   "metadata": {},
   "source": [
    "# For QnA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c89ce6a",
   "metadata": {},
   "source": [
    "## Sentiment Analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "08fc1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_dict = {'manipulate':-1,'manipulative':-1,'jamescharlesiscancelled':-1,'jamescharlesisoverparty':-1,\n",
    "#             'pedophile':-1,'pedo':-1,'cancel':-1,'cancelled':-1,'cancel culture':0.4,'teamtati':-1,'teamjames':1,\n",
    "#             'teamjamescharles':1,'liar':-1}\n",
    "word_dict = {'increase':1, 'increased':1, 'increases':1, \"increasing\":1, \"increasingly\":1, \"expand\":1,\n",
    "'expanded':1, \"expanding\":1, \"expands\":1, \"expansion\":1, \"expansions\":1, \"grow\":1,\n",
    "\"grows\":1, \"grew\":1, \"growth\":1, \"growths\":1, \"improve\":1, \"improved\":1, \"improves\":1,\n",
    "\"improvement\":1, \"improvements\":1, \"strong\":1, \"stronger\":1, \"strongest\":1, \"strongly\":1, \"decline\":-40, \n",
    "\"declined\":-40, \"declines\":-40, \"declining\":-40, \"deteriorate\":-40, \"deteriorates\":-40,\n",
    "\"deteriorated\":-40, \"deteriorating\":-40, \"compress\":-40, \"compressed\":-40, \"compresses\":-40,\n",
    "\"compressing\":-40, \"compressible\":-40, \"compression\":-40, \"reduce\":-40, \"reduces\":-40,\n",
    "\"reduced\":-40, \"reducing\":-40, \"reduction\":-40, \"reductions\":-40, \"weak\":-40, \"weaker\":-40,\n",
    "\"weakest\":-40, \"weaken\":-40, \"weakens\":-40, \"weakened\":-40, \"weakening\":-40, \"weakness\":-40,\n",
    "\"weaknesses\":-40}\n",
    "\n",
    "\n",
    "sid.lexicon.update(word_dict)\n",
    "\n",
    "list1 = []\n",
    "for i in df['Q&A']:\n",
    "    list1.append((sid.polarity_scores(str(i)))['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "724b4606",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score_qna'] = pd.Series(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "34ca7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_category(sentiment):\n",
    "    label = ''\n",
    "    if(sentiment>0.9):\n",
    "        label = 'Positive'\n",
    "    elif(sentiment>0.6):\n",
    "        label = 'Neutral'\n",
    "    else:\n",
    "        label = 'Negative'\n",
    "    return(label)\n",
    "\n",
    "df['sentiment_category_analyser_qna'] = df['score_qna'].apply(sentiment_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "789ff50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    302\n",
       "Negative     60\n",
       "Neutral       4\n",
       "Name: sentiment_category_analyser_qna, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment_category_analyser_qna.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "66264c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.32786885245901637\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in range(len(df['Sentiment'])):\n",
    "    if df['Sentiment'][i] == df['sentiment_category_analyser_qna'][i]:\n",
    "        c += 1\n",
    "print(\"Accuracy: \", c/len(df['Sentiment']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c16af24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.21258278145695364\n",
      "Recall:  0.33229166666666665\n",
      "F1 score:  0.23813953488372094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Precision: \", precision_score(df['Sentiment'], df[\"sentiment_category_analyser_qna\"], average=\"macro\"))\n",
    "print(\"Recall: \", recall_score(df['Sentiment'], df[\"sentiment_category_analyser_qna\"], average=\"macro\"))\n",
    "print(\"F1 score: \", f1_score(df['Sentiment'], df[\"sentiment_category_analyser_qna\"], average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da0466",
   "metadata": {},
   "source": [
    "## Text blob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cdda369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# compute sentiment scores (polarity) and labels\n",
    "sentiment_scores_tb = [round(TextBlob(article).sentiment.polarity, 2) for article in df['Q&A']]\n",
    "sentiment_category_tb = ['Positive' if score > 0 \n",
    "                             else 'Negative' if score < 0 \n",
    "                                 else 'Neutral' \n",
    "                                     for score in sentiment_scores_tb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0206ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment_category_tb_qna'] = pd.DataFrame(sentiment_category_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "96ff412d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    366\n",
       "Name: sentiment_category_tb_qna, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment_category_tb_qna.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0dc074bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.34972677595628415\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in range(len(df['Sentiment'])):\n",
    "    if df['Sentiment'][i] == df['sentiment_category_tb_qna'][i]:\n",
    "        c += 1\n",
    "print(\"Accuracy: \", c/len(df['Sentiment']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d60453e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.11657559198542805\n",
      "Recall:  0.3333333333333333\n",
      "F1 score:  0.17273954116059378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Precision: \", precision_score(df['Sentiment'], df[\"sentiment_category_tb_qna\"], average=\"macro\"))\n",
    "print(\"Recall: \", recall_score(df['Sentiment'], df[\"sentiment_category_tb_qna\"], average=\"macro\"))\n",
    "print(\"F1 score: \", f1_score(df['Sentiment'], df[\"sentiment_category_tb_qna\"], average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9625cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #check presence of these words in text\n",
    "# revenue = {'sales', 'revenue', 'top line', 'top bottom line', 'net revenue', 'organic revenue growth', \n",
    "#            'organic sales growth', 'operational sales'}\n",
    "# earnings = {'eps', 'earnings', 'earnings per share',  'net income', 'bottom line', 'top bottom line'}\n",
    "# profitibiality = {'margin', 'gross margin', 'operating margin', 'return invested capital', 'return capital'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b076f",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a342c",
   "metadata": {},
   "source": [
    "https://www.kdnuggets.com/2018/08/emotion-sentiment-analysis-practitioners-guide-nlp-5.html\n",
    "\n",
    "https://towardsdatascience.com/sentimental-analysis-using-vader-a3415fef7664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec42ca6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
